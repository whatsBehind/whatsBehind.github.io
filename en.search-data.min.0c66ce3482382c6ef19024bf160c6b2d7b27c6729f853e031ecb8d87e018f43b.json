[{"id":0,"href":"/docs/programming/project/online-chat/","title":"Online Chat","section":"Project","content":" Demo # GitHub\nHigh Level Architecture # This is an online chat system built with BIO (Blocking IO) Using Java. Each client has two socket connections with the server, one connection supports message push mode and another one supports message pull mode.\nThe system now supports below features:\nLogin Pull online users Online chat Logoff Because of supports for push and pull modes, features like\nUpload/Download files Group chat can be easily added in the system. However, this project is just for learning purpose, so I didn\u0026rsquo;t spend too much time on it. Key Components # Client # Server Listener It\u0026rsquo;s basically a class extending Thread containing a socket connected with the server. In its run() method, it listens to InputStream of the socket which takes messages from the server. The socket in this component connects to Publisher from the server to support message push mode\npublic class ServerListener extends Thread { private Socket socket; private boolean listening = true; public ServerListener(Socket socket, User user) { this.socket = socket; this.user = user; } public void run() { try { while(listening) { ObjectInputStream ois = new ObjectInputStream(socket.getInputStream()); Message response = (Message) ois.readObject(); MessageType type = response.getType(); switch(type) { ... // Operations } } } catch (IOException | ClassNotFoundException e) { e.printStackTrace(); } } } Online Chat Client It\u0026rsquo;s a client class containing another socket connecting with the server. It supports message pull mode, which is that client sends a request to server and receives a response, and it\u0026rsquo;s a synchronous request. It has two private methods sendRequest and receiveResponse which are used to support communication with the server.\npublic class OnlineChatClient { private Socket client; private ObjectOutputStream oos; private ObjectInputStream ois; private void sendRequest(Message request) throws IOException { oos = new ObjectOutputStream(client.getOutputStream()); oos.writeObject(request); } private Message receiveResponse() throws IOException, ClassNotFoundException { ois = new ObjectInputStream(client.getInputStream()); return (Message) ois.readObject(); } } Server # Message Publisher The name of this component is descriptive. Its duty is to publish a message to a corresponding client and receive the response from the server. It works with Server Listener in clients to support message push mode. Each message publisher has a 1 to 1 relationship with the client. All message publishers are managed by Message Publisher Manager\npublic class MessagePublisher { private Socket socket; private ObjectOutputStream oos; public void publish(Object o) throws IOException { oos = new ObjectOutputStream(socket.getOutputStream()); oos.writeObject(o); } } Message Publisher Manager It maintains a Map to store all message publishers. The map\u0026rsquo;s key is user id and the value is the message publisher. It provides methods like add() get(String userId) and delete(String userId) to manage all message publishers.\npublic class MessagePublisherManager { private final static Map\u0026lt;String, MessagePublisher\u0026gt; publishers = new ConcurrentHashMap\u0026lt;\u0026gt;(); public static boolean contains(User user) { final String id = user.getId(); return publishers.containsKey(id); } public static MessagePublisher add(User user, Socket socket) { if (contains(user)) { return publishers.get(user); } final String id = user.getId(); MessagePublisher publisher = new MessagePublisher(user, socket); return MessagePublisherManager.publishers.put(id, publisher); } public static MessagePublisher get(String userId) { return publishers.get(userId); } public static MessagePublisher get(User user) { return get(user.getId()); } public static void remove(User user) { publishers.remove(user.getId()); } } Client Listener It is similar to Server Listener in clients. It\u0026rsquo;s a Thread subclass waiting for message from the server. The thread in the most time is blocked at line\nMessage response = (Message) ois.readObject(); Once messages sent to the socket\u0026rsquo;s receive queue (InputStream), it reads the message and performs corresponding operation and returns a response to the client.\npublic class ClientListener extends Thread { private Socket socket; private ObjectOutputStream oos; private boolean listening = true; public void run() { try { while(listening) { ObjectInputStream ois = new ObjectInputStream(socket.getInputStream()); Message response = (Message) ois.readObject(); MessageType type = response.getType(); switch(type) { ... // Operations } } } catch (IOException | ClassNotFoundException e) { e.printStackTrace(); } } private void sendResponse(Message message) throws IOException { oos = new ObjectOutputStream(socket.getOutputStream()); oos.writeObject(message); } } Client Listener Manager It manages all client listeners in a Map, supporting methods like add, get and remove.\npublic class ClientListenerManager { private final static Map\u0026lt;String, ClientListener\u0026gt; clientListeners = new ConcurrentHashMap\u0026lt;\u0026gt;(); private static ObjectOutputStream oos; public static void add(Socket socket, User user) throws IOException { Message response = Message.builder() .type(MessageType.CONNECT) .content(gson.toJson(BaseResponse.builder().successful(true).build())) .timeStamp(new Date().toString()).build(); oos = new ObjectOutputStream(socket.getOutputStream()); oos.writeObject(response); ClientListener listener = new ClientListener(socket, user); clientListeners.put(user.getId(), listener); listener.start(); } public static ClientListener get(User user) { final String id = user.getId(); return clientListeners.get(id); } public static ClientListener get(String id) { return clientListeners.get(id); } public static void remove(User user) { final String id = user.getId(); clientListeners.remove(id); } } Supported Features # Login # Client creates a new Socket connecting to port 9999 in local host (Server and clients are in local host) by sending below message. Message type is USER_LOGIN Before sending the message, user needs to enter user id and password Message request = Message.builder() .sender(user.getId()) .timeStamp(new Date().toString()) .type(MessageType.USER_LOGIN) .content(gson.toJson(user)) .build(); Server receives the login message from the client First server checks database if the user enters valid user id and password (Not implemented) After id and password validations, server creates a new MessagePublisher and add it into MessagePublisherManager In the end, server sends back a response to notify the client if login succeeds Client receives response from server. If login succeeded, client start a new ServerListener which is a subclass of Thread to listen to message from server. The thread is blocked when there is no messages from server. Connect: # This is not an API, but a process implicitly done in advance for features like GetOnlineUsers which utilizes OnlineChatClient\nClient creates a new Socket connecting to port 9999 in local host After server receives the request, it starts a new ClientListener, the subclass of Thread, which is listening message from the client. Then server add the ClientListener to ClientListenerManager Server send back response to the client Client receives response from server After above steps, a new socket connection between server and client is built, which supports message pull mode.\nGetOnlineUsers # Client sends a request to server Server checks MessagePublisherManager, get all online users\u0026rsquo; id Server sends a response back to client Client renders online users\u0026rsquo; id in terminal Chat # ClientA sends a request to server containing receiver\u0026rsquo;s id (ClientB) and the message Client listenerA in the server receives the request, it passes the message to message publisherB Message publisherB sends a request containing the message to clientB ClientB responds after receiving the message After message was successfully sent to clientB, client listenerA sends a response to clientA ClientA receives the response Logoff # Client sends a request to the server to logoff Server receives the request, responds to the client. Server close the socket in the client listener, and remove the listener from listener manager Server sends a request to client through message publisher Client receives the request, close socket in the server listen Client responds. Server receives the response from client. Then server closes the socket in message publisher and remove the message listener from listener manager After all aboves steps, all sockets are closed and each listener thread (ServerListener in the client and ClientListener in the server) is terminated.\nTo Be Improved # This system is built on BIO. In server and client sides, there is one thread blocked to listen to messages sent to the input stream of the socket. Thread is expensive because of the memory it occupies and performance influence when CPU switching among different threads Listener is a resource shared by two threads, main thread and the listener thread. Current code doesn\u0026rsquo;t ensure thread safety. The quick fix is to expose InputStream and OutputStream of the socket from the listener, and main thread can only access the two streams by calling the exposed methods. Also, the two methods should be synchronized. "},{"id":1,"href":"/docs/programming/backend/java/thread/start-thread/","title":"Start Thread","section":"Thread","content":" Main Lesson # Java threads are crucial for executing multiple tasks concurrently in a program. Let\u0026rsquo;s dive into this topic:\nWhat is a Thread in Java? üßµ\nIn Java, a thread is the smallest unit of execution within a process. Think of it like a worker who performs a part of a larger task. Creating a Thread üíª\nThere are two ways to create a thread: By extending the Thread class. By implementing the Runnable interface. Example: Let\u0026rsquo;s create a simple thread that prints \u0026ldquo;Hello, Java Threads!\u0026rdquo;. Starting a Thread ‚ú®\nUse the .start() method to begin the execution of a thread. It\u0026rsquo;s like telling our worker, \u0026ldquo;Go ahead and start your task!\u0026rdquo; Thread Lifecycle üìö\nUnderstand the states: New, Runnable, Running, Waiting/Blocked, and Terminated. It\u0026rsquo;s like a day in the life of our worker, from arrival to completion of the task. Synchronization ü§ù\nWhen threads share resources, we need to ensure they don\u0026rsquo;t interfere with each other. It\u0026rsquo;s like coordinating workers to avoid conflicts and ensure smooth operation. Thread Safety üîí\nEnsuring that our threads don\u0026rsquo;t cause data corruption or inconsistent results. Think of it as safety measures in a workplace. Several Ways to Start A Thread # Extends Thread class\npublic class ExtendsThread { public static void main(String[] args) { Thread_1 thread_ = new Thread_1(); thread_.start(); } } class Thread_1 extends Thread { public void run() { System.out.println(\u0026#34;Hello World!\u0026#34;); } } Thread_1 extends Thread class and overrides method run(). We create a Thread_1 object and invoked start() method inherited from parent class Thread to start a new thread. Besides extending Thread class, we can also create a thread by implementing Runnable interface\nImplements Runnable interface\npublic class ImplementsRunnable { public static void main(String[] args) { Thread thread = new Thread(new Thread_2()); thread.start(); } } class Thread_2 implements Runnable { public void run() { System.out.println(\u0026#34;Hello World!\u0026#34;); } } Create FutureTask object\nFutureTask has a Callable field. Callable and Runnable both stand for a task, the difference is that Callable has return value, but Runnable doesn\u0026rsquo;t In below code snippet, we pass the FutureTask to a thread, and start the thread task.get() method is a blocking thread. It stop current thread, which is main here until the task finishes (run() finish in FutureTask) // Create a new future task FutureTask\u0026lt;Integer\u0026gt; task = new FutureTask\u0026lt;\u0026gt;(() -\u0026gt; { log.debug(\u0026#34;running\u0026#34;); Thread.sleep(1000); return 100; }); // Create and start a new thread Thread t = new Thread(task, \u0026#34;Thread_Get_Int\u0026#34;); t.start(); log.debug(\u0026#34;In main thread\u0026#34;); // Blocking method Integer result = task.get(); log.debug(\u0026#34;{}\u0026#34;, result); Open Question: Why do we invoke start() to start a thread, what if I invoke run() directly? # That\u0026rsquo;s a great question about thread management in Java! Let\u0026rsquo;s delve into the difference between invoking start() and run() when dealing with threads.\nUsing start() Method:\nThe start() method is used to begin the execution of a new thread in the Java runtime environment. When start() is called, it performs necessary preparations and creates a new thread in which the run() method will execute. This means the run() method executes in a separate call stack. Key Point: start() enables concurrent execution, aligning with the whole purpose of using threads. Directly Calling run() Method:\nIf you directly call the run() method, it does not start a new thread. Instead, the run() method executes in the current thread\u0026rsquo;s call stack, just like a normal method call. This means no concurrent execution happens; it\u0026rsquo;s just a regular method call. Key Point: Calling run() directly defeats the purpose of threading, as it doesn\u0026rsquo;t utilize the multithreading capabilities of Java. Consequences of Invoking run() Instead of start():\nWhen you call run() directly, you\u0026rsquo;re not utilizing the threading capabilities of Java; your code is executed on the same thread that called run(). This can lead to performance issues if the purpose is to execute tasks concurrently. It essentially turns your thread into a regular object, not a thread of execution. Summary:\nUse start() to actually start a new thread, leading to concurrent execution. Directly calling run() is like any other method call and does not start a new thread. This distinction is crucial for effective multithreading in Java. It\u0026rsquo;s part of ensuring that your program benefits from concurrency and parallelism. ü¶åüíªüßµ public class InvokesRun { public static void main(String[] args) { System.out.println(\u0026#34;Thread for main method \u0026#34; + Thread.currentThread().getName()); RunThread runThread = new RunThread(); StartThread startThread = new StartThread(); runThread.run(); startThread.start(); } } class RunThread extends Thread { public void run() { System.out.println(\u0026#34;Thread for RunThread: \u0026#34; + Thread.currentThread().getName()); } } class StartThread extends Thread { public void run() { System.out.println(\u0026#34;Thread for StartThread: \u0026#34; + Thread.currentThread().getName()); } } "},{"id":2,"href":"/docs/programming/web/security/asymmetric-encryption/","title":"Asymmetric Encryption","section":"Security","content":" What Is Asymmetric Encryption? # Asymmetric encryption, also known as public-key encryption, is a method of encrypting data that involves two separate keys: a public key and a private key. These keys are mathematically linked but not identical, hence the term \u0026ldquo;asymmetric.\u0026rdquo; This method provides a secure way of encrypting and decrypting information, and it\u0026rsquo;s widely used in various forms of digital communication and security protocols\nHow Does It Work? # Key Generation: # A pair of cryptographic keys is generated. The process involves complex algorithms like RSA or ECC, ensuring that these keys are mathematically linked. The public key is designed to be shared, while the private key is kept confidential by the owner.\nThe message encrypted with the public key can only be decrypted by the linked private key and vise verse.\nPublic Key Sharing: # The public key is distributed to anyone who might need to encrypt data intended for the owner. This can be done through public directories, digital certificates, or direct sharing.\nAfter Key Generation and Public Key Sharing,\nA has public key of B, and it own private key (A) B has public key of A, and it own private key (B) Encryption Process: # To send an encrypted message, the sender uses the recipient\u0026rsquo;s public key. This key encrypts the plaintext (original message), transforming it into ciphertext (encrypted message). The encryption is such that only the corresponding private key can efficiently decrypt the ciphertext.\nTransmission: # The ciphertext, now encrypted and secure, is transmitted over the network. Even if intercepted, the message remains secure because it can only be decrypted by the private key holder.\nDecryption: # The recipient uses their private key to decrypt the message. The private key reverses the encryption process, converting the ciphertext back into readable plaintext. Since only the intended recipient possesses the private key, the confidentiality and integrity of the message are maintained.\nReference # YouTube Video\n"},{"id":3,"href":"/docs/programming/backend/java/nio/byte-buffer/","title":"Byte Buffer","section":"Nio","content":" Introduction # Java ByteBuffer is a class in Java\u0026rsquo;s java.nio package. It\u0026rsquo;s used for reading and writing data to and from buffers efficiently. Buffers are blocks of memory that can store data temporarily. ByteBuffer is particularly useful when dealing with I/O operations and for high-performance applications. üìò\nByteBuffer can be used in two modes:\nRead Mode: You can read data from the buffer. üí° Write Mode: You can write data to the buffer. üí° Practical Example # // Create a new ByteBuffer ByteBuffer buffer = ByteBuffer.allocate(10); // Write data into the buffer buffer.put((byte) 10); buffer.put((byte) 20); // Flip the buffer to read mode buffer.flip(); // Read data from the buffer byte first = buffer.get(); byte second = buffer.get(); In this example, we first write two bytes into the buffer and then read them back.\nImportant Concepts and Operations # Capacity, Limit, and Position: ByteBuffer has three important properties:\nCapacity: The maximum number of bytes it can hold. It\u0026rsquo;s set when the buffer is created and cannot be changed. Limit: The limit is the index of the first element that should not be read or written. It can change as you read/write data. Position: The next element to be read or written. Position will increase as you read or write data. Operations # Create a new ByteBuffer\nByteBuffer buffer = ByteBuffer.allocate(10); Write ByteBuffer\nPut single byte ByteBuffer buffer = ByteBuffer.allocate(10); buffer.put((byte) \u0026#39;a\u0026#39;); Put byte array ByteBuffer buffer = ByteBuffer.allocate(10); buffer.put(new byte[]{\u0026#39;a\u0026#39;}); Read ByteBuffer\nflip(): switch to read mode\nbuffer = ByteBuffer.allocate(10); buffer.put(new byte[]{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;}); Here we create a new ByteBuffer, and write four bytes to the ByteBuffer. The ByteBuffer is still in write mode, and to switch to read mode, we can invoke flip() method.\nbuffer.flip(); flip() updates values of limit and position\nthis.limit = position; this.position = 0; get(): read one byte and increment position\nbuffer.flip(); char data = (char) buffer.get(); get(int i): read byte of index w/o position change\nbuffer.flip(); char data = (char) buffer.get(0); // \u0026#39;a\u0026#39; pointer position doesn\u0026rsquo;t increment clear() \u0026amp; compact(): switch from read mode to write mode\nclear(): clear() resets position to 0, and limit to the capacity of the ByteBuffer. It doesn\u0026rsquo;t erase the data, but prepares a new write operation for the buffer.\nbuffer.put(new byte[]{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;}); buffer.flip(); buffer.get(); buffer.get(); buffer.clear(); compact(): compact() moves unread data to the beginning of the buffer, and sets position after the last unread byte and limit to the capacity of the buffer.\nUse case: When you have partially processed the data in the buffer and want to keep remaining unprocessed data while sill making room for the new data to be added buffer.put(new byte[]{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;}); buffer.flip(); buffer.get(); buffer.get(); buffer.compact(); Manipulate position pointer\nrewind(): reset position back to 0\nByteBuffer buffer = ByteBuffer.allocate(10); buffer.put(new byte[]{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;}); buffer.rewind(); rewind() only does one thing that is to reset position to 0. After rewind, you can write/read from the beginning of the ByteBuffer\nmark() and reset(): bookmark position and re-visit\nByteBuffer buffer = ByteBuffer.allocate(10); buffer.put(new byte[]{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;}); buffer.flip(); buffer.get(); buffer.get(); buffer.mark(); buffer.get(); buffer.get(); buffer.reset(); mark() and reset() introduce a new pointer mark in ByteBuffer, and the two methods are normally used together. Value of mark in most case is -1. When mark() is invoked, current position will be remembered by assigning position to mark\nIn above code snippet, after remembering position (mark()), we continue read two more bytes from the ByteBuffer where position is 4. reset() resets position to previous mark which is 2.\nComparing to rewind() which can only reset position to 0, mark() and reset() have enhanced feature which bookmarks position and resets position to previous mark\nWork with Channel\nChannel\nChannel is an important component in NIO, and it is like Stream in BIO. Different from Stream, Channel can be used bi-directional and can be used in conjunction with Buffer\nWhen Using Channel and Buffer, data can be read from a Channel into a Buffer or written from a Buffer into a Channel Read Channel\ntry (FileChannel channel = new FileInputStream(\u0026#34;~/example.txt\u0026#34;).getChannel()) { channel.read(buffer); } Here we get the Channel from FileInputStream, and read data from the channel into a ByteBuffer\nWrite Channel\ntry (FileChannel channel = new FileOutputStream(\u0026#34;~/example.txt\u0026#34;).getChannel()) { ByteBuffer buffer = ByteBuffer.allocate(10); buffer.put(new byte[]{\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;}); // Need to switch byteBuffer to read mode before writing to channel buffer.flip(); int len = channel.write(buffer); log.debug(String.format(\u0026#34;Write %s bytes to file\u0026#34;, len)); } Work with String\nfrom string to buffer String.getBytes():\nbuffer = ByteBuffer.allocate(16); buffer.put(\u0026#34;Hello World\u0026#34;.getBytes()); charset:\nByteBuffer buffer = StandardCharsets.UTF_8.encode(\u0026#34;Hello World\u0026#34;); ByteBuffer.wrap():\nByteBuffer buffer = ByteBuffer.wrap(\u0026#34;Hello World\u0026#34;.getBytes()); from buffer to string charset: ByteBuffer buffer = StandardCharsets.UTF_8.encode(\u0026#34;Hello World\u0026#34;); String str = StandardCharsets.UTF_8.decode(buffer).toString(); "},{"id":4,"href":"/docs/programming/aws/cloudformation/","title":"CloudFormation","section":"Aws","content":" CloudFormation # Resources # Resource Type Reference\nResources Introduction\nSyntax # Resources: Logical ID: Type: Resource type Properties: Set of properties Logical ID: A unique logical ID for that resource, which can be referenced by other parts in the template\nResource Type: An identifier of the resource that you are declaring\nResource Type Reference Resource Properties: Additional options that you can specify for a resource\nParameters (Optional) # Guide Parameters allow you to input custom values for your template. You can think the template as a module or a function with arguments. Each time creating or updating a stack using the template is like invoking the function with parameters you defined in the template.\nSyntax # Parameters: ParameterLogicalID: Type: DataType ParameterProperty: value Example Parameters: InstanceTypeParameter: Type: String Default: t2.micro AllowedValues: - t2.micro - m1.small - m1.large Referencing a Parameter # User Ref intrinsic function to reference a parameter\nExample Ec2Instance: Type: AWS::EC2::Instance Properties: InstanceType: Ref: InstanceTypeParameter ImageId: ami-0ff8a91507f77f867 Pseudo Parameter # Guide Parameters are predefined by AWS CloudFormation. You can think them as environment variables\nMappings (Optional) # Guide Mappings are fixed values in your CloudFormation template. Different from Parameters which are unknown before creating the stack, Mappings are hard coded in the template and are known in advance\nYou can think Mappings as static configurations in your project\nSyntax # YAML # Mappings: MappingName: PrimaryKey01: SecondaryKey01: Value01 PrimaryKey02: SecondaryKey02: Value02 PrimaryKey03: SecondaryKey03: Value03 Example # Mappings: DependencyAwsAccountMapping: us-ease-1: dependency01: 123456789012 dependency02: 123456789013 us-west-2: dependency01: 987654321098 dependency02: 987654321987 Find a Value in a Mapping # You can use intrinsic function !FindInMap\nSyntax !FindInMap [MappingName, PrimaryKey, Secondary] Above function returns value01\nExample AWSTemplateFormatVersion: \u0026#34;2010-09-09\u0026#34; Mappings: RegionMap: us-east-1: HVM64: ami-0ff8a91507f77f867 HVMG2: ami-0a584ac55a7631c0c us-west-2: HVM64: ami-0bdb828fd58c52235 HVMG2: ami-066ee5fd4a9ef77f1 Resources: myEC2Instance: Type: \u0026#34;AWS::EC2::Instance\u0026#34; Properties: ImageId: !FindInMap [RegionMap, !Ref \u0026#34;AWS::Region\u0026#34;, HVM64] InstanceType: m1.small Outputs (Optional) # Guide\nCross-stack Reference: Outputs section declares output values that can be imported into other templates\nYou can\u0026rsquo;t delete the stack if its outputs are referenced by other stacks\nSyntax # Outputs: LogicalId: Description: Information about the value Value: Value to return Export: Name: Name of resource to export You can think above export statements as below to better understand\nexport LogicalId as Name; Import Outputs into Other Stacks # Output from StackA\nOutputs: WebServerSecurityGroup: Description: The security group ID to use for public web servers Value: \u0026#39;Fn::GetAtt\u0026#39;: - WebServerSecurityGroup - GroupId Export: Name: \u0026#39;Fn::Sub\u0026#39;: \u0026#39;${AWS::StackName}-SecurityGroupID\u0026#39; Import into StackB\nResources: WebServerInstance: Type: \u0026#39;AWS::EC2::Instance\u0026#39; Properties: InstanceType: t2.micro ImageId: ami-a1b23456 NetworkInterfaces: - GroupSet: - Fn::ImportValue: \u0026#39;Fn::Sub\u0026#39;: \u0026#39;${NetworkStackNameParameter}-SecurityGroupID\u0026#39; Conditions (Optional) # Guide The Conditions section contains statements that define the circumstances under which entities are created or configured\nDefine a Condition # AWSTemplateFormatVersion: 2010-09-09 Parameters: EnvType: Description: Environment type. Default: test Type: String AllowedValues: - prod - test ConstraintDescription: must specify prod or test. Conditions: IsProd: !Equals - !Ref EnvType - prod Define a Nested Condition # Conditions: IsProd: !Equals - !Ref EnvType - prod CreateBucket: !Not - !Equals - !Ref BucketName - \u0026#39;\u0026#39; CreateBucketPolicy: !And - !Condition IsProd - !Condition CreateBucket Use Conditions # Resources: EC2Instance: Type: \u0026#39;AWS::EC2::Instance\u0026#39; Condition: IsProd Rules (Optional) # Guide Rules validates parameters passed to a template during creation or updates of a stack\nWorking with Rules # Each template rule contains two properties:\nRule Condition (Optional) - determine when a rule takes effect Each rule can only have one condition If the condition is not defined, then the rule\u0026rsquo;s assertions always take effect Rule Assertion (Required) - describe what values users can use for a specific parameter One rule can have multiple assertions Example # Rules: testInstanceType: RuleCondition: !Equals - !Ref Environment - test Assertions: - Assert: \u0026#39;Fn::Contains\u0026#39;: - - a1.medium - !Ref InstanceType AssertDescription: \u0026#39;For a test environment, the instance type must be a1.medium\u0026#39; prodInstanceType: RuleCondition: !Equals - !Ref Environment - prod Assertions: - Assert: \u0026#39;Fn::Contains\u0026#39;: - - a1.large - !Ref InstanceType AssertDescription: \u0026#39;For a production environment, the instance type must be a1.large\u0026#39; Change Set # Guide Change Set allows you to preview how existing resources could be affected, like adding or deleting a resource, once you update the template or parameters for a stack\nNested Stack # Guide Nested stacks are stacks created as part of other stacks. You create a nested stack within another stack by using the AWS::CloudFormation::Stack resource.\nYou can think nested stack as a function invoked by other modules (stacks). Similar with functions which have arguments and return values, nested stacks have parameters and outputs\nExample # Nested Stack Template\nAWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Parameters: BucketName: Type: String Description: The name of the S3 bucket Resources: MySampleBucket: Type: AWS::S3::Bucket Properties: BucketName: !Ref BucketName Outputs: CreatedBucketName: Description: Name of the created S3 bucket Value: !Ref MySampleBucket Export: Name: !Sub \u0026#34;${AWS::StackName}-BucketName\u0026#34; Parent Stack Template\nAWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; Resources: MyNestedStack: Type: AWS::CloudFormation::Stack Properties: TemplateURL: \u0026#39;https://s3.amazonaws.com/mybucket/NestedStack.yaml\u0026#39; Parameters: BucketName: MyCustomBucketName Outputs: NestedStackBucketName: Description: The name of the bucket created in the nested stack Value: !GetAtt MyNestedStack.Outputs.CreatedBucketName Function Analogy # As I mentioned above, we can think nested stacks as functions invocations. We can transform above examples to a pseudo-code to illustrate the idea\nNested Function\ndef nested_function(bucket_name): created_bucket_name = create_bucket(bucket_name) return created_bucket_name Parent Function\ndef parent_function(): # Specify the bucket name to pass to the nested function (like Parameters in CloudFormation). bucket_name = \u0026#34;MyCustomBucketName\u0026#34; # Call the nested function, mimicking the creation of the nested stack. created_bucket_name = nested_function(bucket_name) # Output the result (mimicking the Outputs in CloudFormation). return created_bucket_name # Run the parent function to simulate the stack deployment. parent_function() CloudFormation Drift # A CloudFormation Drift is that the actual configuration of a stack is drifted or different from the template of the stack, in other words, the stack was modified manually\nStack Policy # A Stack Policy is a JSON file that defines the update actions that are allowed on specific resources during stack updates\n"},{"id":5,"href":"/docs/programming/web/network/dns/","title":"DNS","section":"Network","content":" What Is DNS? # DNS, which stands for Domain Name System, is a fundamental component of the internet\u0026rsquo;s infrastructure. It functions like a phone book for the internet by translating human-friendly domain names (like www.example.com) into IP addresses (like 192.0.2.1) that computers use to identify each other on the network.\nHierarchy of Domain Names # Root Level Domain: The root level is the highest level in the DNS hierarchy and is represented by a dot (.) but is typically not visible in domain names. Root servers are the backbone of DNS, directing traffic to the correct Top-Level Domain (TLD) servers.\nTop-Level Domain (TLD): TLDs are the part of the domain name to the right of the dot. They are broadly categorized into two types: generic TLDs (gTLDs) like .com, .org, .net, and country code TLDs (ccTLDs) like .uk, .de, .ca. The TLD serves as a key part of the domain, indicating either the nature of the domain (like .com for commercial) or the geographical location (like .uk for the United Kingdom).\nDomain (Second-Level Domain): The domain or second-level domain is the segment of a domain name that directly precedes the TLD. For businesses or entities, this part of the domain name is often their brand or identity. For example, in google.com, \u0026ldquo;google\u0026rdquo; is the domain name chosen by the entity.\nSubdomain: Subdomains are additional parts of the domain that are added to the left of the main domain and separated by dots. They are used to organize different sections or functions of a website. For instance, a company might use a subdomain for its blog (like blog.example.com) or a specific product (like product.example.com).\nDNS Resolution Process for www.google.com # User Requests the Domain:\nThe user enters www.google.com into their web browser. Browser Checks Cache:\nThe browser checks its own cache to see if it already has the IP address for www.google.com. Query to DNS Resolver:\nIf the IP address is not in the browser cache, the browser sends a query to a DNS resolver, typically provided by the ISP or a third-party service. DNS Resolver Checks Cache:\nThe DNS resolver checks its cache to see if it has a recent record of the IP address for www.google.com. DNS Resolver Queries Root Server:\nIf the IP address is not in the resolver\u0026rsquo;s cache, it queries one of the root name servers, which provides a referral to the TLD name servers for .com. Query to .com TLD Name Server:\nThe resolver queries the .com TLD name server, which directs it to the name servers for the google.com domain. Query to google.com Name Server:\nThe resolver queries the google.com name servers to get the IP address for www.google.com. Resolver Receives IP Address:\nThe google.com name server responds with the IP address for www.google.com. DNS Resolver Caches the Response:\nThe DNS resolver caches the IP address for a specified time based on the TTL value. Resolver Returns IP Address to Browser:\nThe resolver sends the IP address back to the browser. Browser Caches the Response:\nThe browser caches the IP address for future use. Browser Connects to the IP Address:\nThe browser uses the IP address to establish a connection to the server hosting www.google.com, allowing the user to access the website. Reference # Amazon Route 53 Bilibili Video "},{"id":6,"href":"/docs/programming/backend/java/netty/event-loop-group/","title":"EventLoop \u0026 EventLoopGroup","section":"Netty","content":" EventLoop \u0026amp; EventLoopGroup # EventLoop # What is an EventLoop?\nAn EventLoop in Netty is a fundamental component that handles all the events related to a single Channel.\nHow does EventLoop work?\nSingle Threaded: Each EventLoop is bound to a single thread, and each Channel is registered with one EventLoop. This means all I/O operations of a Channel are always executed by the same thread, ensuring thread safety and consistency.\nEvent Processing Loop: The EventLoop continuously checks for new events in its loop and processes them. Events might include connection acceptance, data read/write, or disconnection.\nTask Queue: Besides I/O operations, EventLoops have a task queue for tasks that are not directly related to I/O operations. This ensures that these tasks are also executed in the same thread, maintaining thread safety.\nEventLoopGroup # What is EventLoopGroup? An EventLoopGroup is a collection of EventLoop instances in Netty. It\u0026rsquo;s responsible for managing these EventLoops, which are the core components handling I/O operations and events for Channels (a connection or a socket).\nRoles of EventLoopGroup?\nBoss and Worker Groups: In server-side applications, there are typically two EventLoopGroups. The \u0026lsquo;boss\u0026rsquo; group accepts incoming connections and hands them over to the \u0026lsquo;worker\u0026rsquo; group, which then handles the actual I/O operations. See boss-and-work How does EventLoopGroup work?\nWhen a client attempts to connect to the server, this connection request first arrives at the boss EventLoopGroup. The boss EventLoopGroup accepts the connection and registers it with an EventLoop in the worker EventLoopGroup. Once a connection is assigned to an EventLoop in the worker group, that EventLoop is responsible for all the events and operations associated with that connection. The EventLoop in the worker EventLoopGroup processes incoming data, sends responses, and can execute tasks like message decoding, business logic processing, and message encoding. Examples # Execute a single task\nCode\nEventLoopGroup group = new NioEventLoopGroup(2); group.next().execute(() -\u0026gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { throw new RuntimeException(e); } log.debug(\u0026#34;Hello World!\u0026#34;); }); log.debug(\u0026#34;Hello main!\u0026#34;); Execution Result\n22:10:25.111 [main] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello main! 22:10:26.111 [nioEventLoopGroup-2-1] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello World! group.next() returns a EventLoop\nThe EventLoop can execute a Runnable task in its thread\nMain thread is not blocked\nExecute scheduled tasks\nCode EventLoopGroup group = new NioEventLoopGroup(2); AtomicInteger count = new AtomicInteger(0); group.next().scheduleAtFixedRate(() -\u0026gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { throw new RuntimeException(e); } log.debug(\u0026#34;Hello EventLoop-{}!\u0026#34;, count.getAndIncrement()); }, 0, 1, TimeUnit.SECONDS); Execution Result 22:10:26.112 [nioEventLoopGroup-2-2] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello EventLoop-0! 22:10:27.112 [nioEventLoopGroup-2-2] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello EventLoop-1! 22:10:28.113 [nioEventLoopGroup-2-2] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello EventLoop-2! 22:10:29.113 [nioEventLoopGroup-2-2] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello EventLoop-3! 22:10:30.114 [nioEventLoopGroup-2-2] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello EventLoop-4! 22:10:31.114 [nioEventLoopGroup-2-2] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello EventLoop-5! 22:10:32.114 [nioEventLoopGroup-2-2] DEBUG com.whatsbehind.netty_.component.EventLoopGroup_ - Hello EventLoop-6! ... "},{"id":7,"href":"/docs/programming/system-design/monitoring/metric-log/","title":"Metric \u0026 Log","section":"Monitoring","content":" Introduction # Metrics and logs are important for a service. They help to monitor the health of a service and can also be used to debug when service goes down or crashes. This post won\u0026rsquo;t discuss importance of monitoring system but focuses on how to design a monitoring system in your host\nRequirements # Upload Data to A Web Monitoring System # Logs are records of code execution that are stored somewhere in your host. Log files rotate with given interval, like 1 hr. You log files may look like below:\nservice.log-2024-01-01-1 There are some limitations to store logs in you host:\nSize limitation Depends on how long you want to retain your logs. However, regardless the log retention, 5 years or 10 years, it is a waste of disk storage to store logs in you host Limited query function When debugging service issues, you only care about specific log patterns within a range of time. What you can do is to use regular expression and grep to query the logs which is not handy. Apart from that, it is hard to virtualize the metrics for your system Considering above limitation, a good solution is to upload your logs and metrics to a monitoring system (like AWS CloudWatch) which\nhas unlimited storage provides out-of-box query features is able to virtualize your metrics monitors metrics and triggers actions if needed and more\u0026hellip; Decouple Data Collection and Publication # To upload data to a monitoring system, we can invoke provided APIs. However, it is not a good practice to call the APIs for each single log or metric in your service code considering a lot of network traffic and low efficiency\nThe better way is to decouple the process of emitting logs and metrics with publishing them. One solution is to buffer your logs and metrics in you hosts and have an out-of-process tool that publishes the records to remote machines\nservice.log service.metrics SDKs to Emit Logs and Metrics # Comparing with metrics, logs are easier to format. The most basic log should contain two parts, timestamp and message. Timestamp is the time when the log is emitted and message contains the execution details, including class and code line that emit the log, log level (INFO, DEBUG, WARNING, ERROR), and custom message.\nMetrics are more complex which contains more information. The SKD should have a model class for the metric. Also, it should provide APIs to emit the metrics which serializes the metric instance to a string with predefined format to the buffer files\nSample codes\nMetric metric = new Metric(); metric.setTime(...); metric.setName(...); metric.setValue(...); ... metric.emit(); Sample metric string\nThe contents within delimiter ----- is a metric serialization containing all parameters of a metric\n----- time: ... name: ... value: ... ... ----- Agent to publish metrics and logs # We should have a tool to publish metrics and logs to remote monitoring system. It could be out-of-process, so it doesn\u0026rsquo;t impact your service. It periodically reads log and metric files and uploads them. To balance the traffic and size of one request, selecting a proper time interval is important\nArchitecture # Components # Service # Your service that is running in the host and generating logs and metrics. It utilizes APIs from log/metric SKD to write logs and metrics to local files. The SDK should provide below features:\nMetric model APIs to write log and emit metric Serialize metric to a specific schema that is understandable by the log/metric agent Rotate log/metric files Metric/Log Files # Files that buffer logs and metrics generated by the service\nMetric/Log Agent # An out-of-process software that\npolls data from metric/log files transform metric schema to specific format that is predefined by the cloud monitoring system periodically push metrics and logs to the remote system Cloud Monitoring System # A third party tool that stores your metrics and logs. It provides some feature like data virtualization, log query, metric action triggering etc\u0026hellip;\nConcepts # Metric # A metric is a behavior of your service or system. It is easier to explain it using examples. Common metrics for a service including count, latency, errors of API calls.\nA metric is a collection of multiple data point which is one measurement. For example, when you receive an API request, the count metric should have one data point with value 1, which means your API gets called once. You record that time when receiving the request and when you finish the process before respond to the client, you record current time. The subtraction between endTime and startTime is the value of one latency data point. If the API process fails, then data point of error with value 1 is recorded.\nSchema # Metric: { nameSpace: string, unit: string, dimensions: { key: string, value: string } dataPoints: [ { timestamp: date, value: number/string } ] } Above is a simple schema of AWS CloudWatch metric.\nnameSpace: Group name of your metrics. You manage your metrics under different groups. You can create groups based on service name, resource type etc\u0026hellip; unit: The unit for the value of metric\u0026rsquo;s data point, i.e, COUNT, MILLI_SECONDS dimensions: Map of key value pairs, which are attributes of your metric dataPoints: Collection of metric measurements timestamp: The time when the data point is recorded value: The value for one data point, like ONE API call, 50 ms latency "},{"id":8,"href":"/docs/programming/backend/java/nio/blocking-mode/","title":"Blocking Mode","section":"Nio","content":" Blocking Mode # This post will introduce the blocking mode of network connection and communication in Java code. We will first wirte both server and client codes. Then demo the blocking mode and its problems.\nCode Example # Server\n@Slf4j public class Server { public static void main(String[] args) throws IOException { ByteBuffer buffer = ByteBuffer.allocate(32); // Create server ServerSocketChannel ssc = ServerSocketChannel.open(); // Server listens to port 9999 at local host ssc.bind(new InetSocketAddress(9999)); log.debug(\u0026#34;Create server listening to port 9999\u0026#34;); List\u0026lt;SocketChannel\u0026gt; socketChannels = new ArrayList\u0026lt;\u0026gt;(); while (true) { // Accept: build connection with client log.debug(\u0026#34;Waiting for client connection...\u0026#34;); SocketChannel socketChannel = ssc.accept(); log.debug(\u0026#34;Build connection with client \u0026#34; + socketChannel.getRemoteAddress()); // Add socketChannel to a list socketChannels.add(socketChannel); // Iterate all SocketChannels and read data from channel and write it to the ByteBuffer for (SocketChannel channel : socketChannels) { log.debug(\u0026#34;Start to read channel from client \u0026#34; + channel.getRemoteAddress()); channel.read(buffer); buffer.flip(); ByteBufferReader.readAll(buffer); buffer.clear(); log.debug(\u0026#34;Complete reading data\u0026#34;); } } } } This is code for the server. First we create a ServerSocketChannel listens to port 9999 of local host We have an infinite while loop where the server accepts connection from clients. Once connection is built, the server creates a new SocketChannel and add it into a list After connection is built, we iterate collection of all SocketChannel, and read data from the channel and write it to a ByteBuffer In the server code above, we add multiple logs before and after client connection and reading data from the channel to better demonstrate blocking mode.\nClient\n@Slf4j public class Client { public static void main(String[] args) throws IOException { SocketChannel sc = SocketChannel.open(); log.debug(\u0026#34;Connecting to server\u0026#34;); sc.connect(new InetSocketAddress(InetAddress.getLocalHost(), 9999)); log.debug(\u0026#34;Connected with server\u0026#34;); while (true) { String input = Scanner_.scanLine(\u0026#34;Input: \u0026#34;); log.debug(\u0026#34;Sending data [{}] to server\u0026#34;, input); sc.write(StandardCharsets.UTF_8.encode(input)); log.debug(\u0026#34;Sent data [{}] to server\u0026#34;, input); } } } In client\u0026rsquo;s code, we connect to the server Then in a while loop, we scan input from terminal and send the data to the server Same as server\u0026rsquo;s code, we add some logs\nDemo # Start the server # Server log:\n20:29:52.904 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Create server listening to port 9999 20:29:52.906 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Waiting for client connection... We start a server, and server is blocked until a client connects to the server. This is the first blocking place in the server code. SocketChannel socketChannel = ssc.accept(); Start clientA # Server log:\n20:33:01.791 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Build connection with client /127.0.0.1:50632 20:33:01.791 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Start to read channel from client /127.0.0.1:50632 Client of port(50632) connects to the server\nServer code is blocked again until recevies any data from clientA\nchannel.read(buffer); ClientA log:\n20:33:01.777 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Connecting to server 20:33:01.780 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Connected with server Input: ClientA conects to the server and waiting for user to type in the terminal Send data from clientA to the server # ClientA log:\nInput: Hello Server from ClientA! 20:38:02.356 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Sending data [Hello Server from ClientA!] to server 20:38:02.358 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Sent data [Hello Server from ClientA!] to server Input: In clientA, we typed Hello Server from ClientA!. After hitting Enter key, the string we just typed was sent to the server. Server log:\n20:38:02.358 [main] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello Server from ClientA! 20:38:02.359 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Complete reading data 20:38:02.359 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Waiting for client connection... Server receives the string Hello Server from ClientA!, and prints the string in the terminal Server is not blocked at reading data from channel, and code is executed again Server is blocked at waiting for connection from another client Send data again from clientA to the server # ClientA log:\nInput: Hello Server from ClientA Again! 20:42:28.083 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Sending data [Hello Server from ClientA Again!] to server 20:42:28.084 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Sent data [Hello Server from ClientA Again!] to server Input: ClientA sends a new string Hello Server from ClientA Again! to the server Server\nServer doesn\u0026rsquo;t have any new logs printed. Because it was blocked at waiting for client connection, no matter how much data sent from clientA, it won\u0026rsquo;t be handled by the server ClientB connects to the server # Client B log:\n20:45:17.107 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Connecting to server 20:45:17.111 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Client - Connected with server Input: A new clientB connects to the server Server log:\n20:45:17.111 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Build connection with client /127.0.0.1:50698 20:45:17.111 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Start to read channel from client /127.0.0.1:50632 20:45:17.111 [main] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello Server from ClientA Again! 20:45:17.111 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Complete reading data 20:45:17.111 [main] DEBUG com.whatsbehind.netty_.nio.blocking.Server - Start to read channel from client /127.0.0.1:50698 ClientB from port(50698) connects to the srever. After new client connection, code is executed again. Server starts to read channels from clientA (port 50632) and prints the data sent some time ago Hello Server from ClientA Again Server is blocked again waiting for clientB sending data\u0026hellip; Summary # As we can see in the demo, blocking mode is low efficient and unable to hanle multiple client connections using one thread. To handle connection and receiving data from multiple clients properly, we have to create a new thread for each connection, which is unrealistic. In next post, we will discuss unblocking mode and its underlying problems.\n"},{"id":9,"href":"/docs/programming/backend/java/netty/channel/","title":"Channel \u0026 ChannelFuture","section":"Netty","content":" Concept # What is Channel? # Definition\nA Channel in Netty represents an open network connection, such as a socket. It\u0026rsquo;s a key abstraction that encapsulates the underlying network transport, such as TCP or UDP.\nRole\nData Communication: A Channel is used for reading data from and writing data to the network. State Management: It keeps track of the state of a network connection (e.g., whether it\u0026rsquo;s open, connected, etc.). What is ChannelFuture? # Definition\nA ChannelFuture represents the result of an asynchronous Channel I/O operation. It\u0026rsquo;s a promise-like mechanism that provides a way to be notified when an asynchronous operation completes.\nUsage # Create a ChannelFuture # ChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer\u0026lt;NioSocketChannel\u0026gt;() { @Override protected void initChannel(NioSocketChannel nioSocketChannel) throws Exception { nioSocketChannel.pipeline().addLast(new StringEncoder()); } }) .connect(new InetSocketAddress(9999)); Channel Connect # Let\u0026rsquo;s add a LoggingHandler to better track the lifecycle of the Channel\nChannelFuture channelFuture = new Bootstrap() .group(new NioEventLoopGroup()) .channel(NioSocketChannel.class) .handler(new ChannelInitializer\u0026lt;NioSocketChannel\u0026gt;() { @Override protected void initChannel(NioSocketChannel nioSocketChannel) throws Exception { + nioSocketChannel.pipeline().addLast(new LoggingHandler()); nioSocketChannel.pipeline().addLast(new StringEncoder()); } }) .connect(new InetSocketAddress(9999)); Synchronous Way # Code\nlog.debug(\u0026#34;Start to connect...\u0026#34;); channelFuture.sync(); log.debug(\u0026#34;Connected\u0026#34;); Channel channel = channelFuture.channel(); channel.writeAndFlush(\u0026#34;Hello World\u0026#34;); Execution Result\n2023-12-31 11:16:55 [main] DEBUG c.w.netty_.component.channel.Client - Start to connect... 2023-12-31 11:16:55 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x77a252c2] REGISTERED 2023-12-31 11:16:55 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x77a252c2] CONNECT: 0.0.0.0/0.0.0.0:9999 2023-12-31 11:16:55 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x77a252c2, L:/127.0.0.1:49310 - R:0.0.0.0/0.0.0.0:9999] ACTIVE 2023-12-31 11:16:55 [main] DEBUG c.w.netty_.component.channel.Client - Connected 2023-12-31 11:16:55 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x77a252c2, L:/127.0.0.1:49310 - R:0.0.0.0/0.0.0.0:9999] WRITE: 11B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 48 65 6c 6c 6f 20 57 6f 72 6c 64 |Hello World | +--------+-------------------------------------------------+----------------+ 2023-12-31 11:16:55 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x77a252c2, L:/127.0.0.1:49310 - R:0.0.0.0/0.0.0.0:9999] FLUSH Explain\nThe lifecycle of Channel and custom logs are printed the in the terminal Two thread: \u0026ldquo;main\u0026rdquo; and \u0026ldquo;worker\u0026rdquo; (nioEventLoopGroup-2-1) are involved Netty build the connection from the client to the server in a non-blocking asynchronous way. Main thread initiates the connection The connection then is handed over to the worker thread The Channel is REGISTERED -\u0026gt; CONNECT -\u0026gt; ACTIVE sync() stops the main thread until the Channel becomes CONNECT Then \u0026ldquo;Hello World\u0026rdquo; is written and flushed Although Netty builds the connection in a non-blocking and asynchronous way, because of using sync() method, the logs are printed in linear order like building the connection synchronously Asynchronous Way / Callback # Code\nchannelFuture.addListener(future -\u0026gt; ((ChannelFuture) future).channel().writeAndFlush(\u0026#34;Hello World\u0026#34;)); Execution Result:\n2023-12-31 11:31:08 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x46b4d807] REGISTERED 2023-12-31 11:31:08 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x46b4d807] CONNECT: 0.0.0.0/0.0.0.0:9999 2023-12-31 11:31:08 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x46b4d807, L:/127.0.0.1:49450 - R:0.0.0.0/0.0.0.0:9999] WRITE: 11B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 48 65 6c 6c 6f 20 57 6f 72 6c 64 |Hello World | +--------+-------------------------------------------------+----------------+ 2023-12-31 11:31:08 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x46b4d807, L:/127.0.0.1:49450 - R:0.0.0.0/0.0.0.0:9999] FLUSH 2023-12-31 11:31:08 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x46b4d807, L:/127.0.0.1:49450 - R:0.0.0.0/0.0.0.0:9999] ACTIVE How does it work?\nIn Netty, operations like reading, writing or connecting over a network channel are asynchronous. When you invoke such an operation, it doesn\u0026rsquo;t complete immediately.\nPerform the Asynchronous Operation: You initiate an operation, like channel connection, which returns a ChannelFuture Attach Listener to ChannelFuture: You use addListener to attach a ChannelFutureListener to this ChannelFuture Completion of the Operation: When the operation you listen to finishes, the callback method is invoked Channel Close # Synchronous Way # Code\nChannel channel = channelFuture.sync().channel(); channel.close(); ChannelFuture closeFuture = channel.closeFuture(); closeFuture.sync(); group.shutdownGracefully(); Execution result\n2023-12-31 21:26:27 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x6675c311] REGISTERED 2023-12-31 21:26:27 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x6675c311] CONNECT: localhost/127.0.0.1:9999 2023-12-31 21:26:27 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x6675c311, L:/127.0.0.1:45504 - R:localhost/127.0.0.1:9999] ACTIVE 2023-12-31 21:26:27 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x6675c311, L:/127.0.0.1:45504 - R:localhost/127.0.0.1:9999] CLOSE 2023-12-31 21:26:27 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x6675c311, L:/127.0.0.1:45504 ! R:localhost/127.0.0.1:9999] INACTIVE 2023-12-31 21:26:27 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x6675c311, L:/127.0.0.1:45504 ! R:localhost/127.0.0.1:9999] UNREGISTERED Asynchronous Way # Code Channel channel = channelFuture.sync().channel(); channel.close(); channel.closeFuture().addListener(future -\u0026gt; { group.shutdownGracefully(); }); Channel Lifecycle # In the execution history of closing the Channel, we can see the lifecycle or state of a Channel\nREGISTERED: The Channel is registered with an EventLoop. This means it\u0026rsquo;s now bound to a particular thread for its I/O operations CONNECT: The Channel is trying to connect to a server ACTIVE: A Channel is considered active when it\u0026rsquo;s connected to a remote peer and ready for I/O operations CLOSE: The Channel closes the connection and releases all underlying resources. A closed Channel can\u0026rsquo;t be reopened INACTIVE: A Channel in the INACTIVE state has been disconnected from the remote endpoint but is not necessarily fully closed. It is potential for reuse UNREGISTERED: The Channel is unregistered from its EventLoop "},{"id":10,"href":"/docs/programming/backend/java/thread/common-methods/","title":"Common Methods","section":"Thread","content":" Common Methods of Java Thread # Sleep(long millis) # Static method that causes the currently executing thread to sleep (temporarily cease execution) for the specified number of milliseconds. If a thread is sleeping, its state is changed to TIMED_WAITING Sleep method could be interrupted by calling interrupt(). After interruption, sleep throws InterruptedException, and thread state is changed to RUNNABLE Example # Code Thread t1 = new Thread(() -\u0026gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { log.debug(\u0026#34;Interrupted\u0026#34;); log.debug(\u0026#34;t1 state: {}\u0026#34;, Thread.currentThread().getState()); } }); t1.setName(\u0026#34;t1\u0026#34;); t1.start(); Thread.sleep(50); log.debug(\u0026#34;t1 state: {}\u0026#34;, t1.getState()); log.debug(\u0026#34;Interrupting thread t1\u0026#34;); t1.interrupt(); Execution results 2024-01-06 12:55:33 [main] DEBUG c.w.thread_.commonmethods.Sleep_ - t1 state: TIMED_WAITING 2024-01-06 12:55:33 [main] DEBUG c.w.thread_.commonmethods.Sleep_ - Interrupting thread t1 2024-01-06 12:55:33 [t1] DEBUG c.w.thread_.commonmethods.Sleep_ - Interrupted 2024-01-06 12:55:33 [t1] DEBUG c.w.thread_.commonmethods.Sleep_ - t1 state: RUNNABLE join() # Waits for the thread to die or terminate. Use case # Code\n@Slf4j public class Join_ { static int result = 0; public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { try { Thread.sleep(50); result++; } catch (InterruptedException e) { throw new RuntimeException(e); } }); t1.start(); log.debug(\u0026#34;result value: {}\u0026#34;, result); } } Execution Result\n2024-01-06 13:18:42 [main] DEBUG c.w.thread_.commonmethods.Join_ - result value: 0 result was printed in the main thread, but its value is not incremented in thread t1 yet, because the thread first sleeps 50ms Solution # Code\n@Slf4j public class Join_ { static int result = 0; public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -\u0026gt; { try { Thread.sleep(50); result++; } catch (InterruptedException e) { throw new RuntimeException(e); } }); t1.start(); + t1.join(); log.debug(\u0026#34;result value: {}\u0026#34;, result); } } Flowchart\nExecution Result\n2024-01-06 13:18:42 [main] DEBUG c.w.thread_.commonmethods.Join_ - result value: 1 In above code snippet, we invoke t1.join() method, which is a blocking method. main thread will wait here until t1 thread terminates State # The thread that is waiting for another thread to terminate is in State WAITING\nCode\nThread t2 invokes t1.join() and waits for t1 to terminate Check t2 state while it is blocked at t1.join() Thread t1 = new Thread(() -\u0026gt; { try { Thread.sleep(50); log.debug(\u0026#34;t1 terminates\u0026#34;); } catch (InterruptedException e) { throw new RuntimeException(e); } }); t1.setName(\u0026#34;t1\u0026#34;); Thread t2 = new Thread(() -\u0026gt; { try { log.debug(\u0026#34;t2 is waiting for t1 terminating\u0026#34;); t1.join(); log.debug(\u0026#34;t2 terminates\u0026#34;); } catch (InterruptedException e) { throw new RuntimeException(e); } }); t2.setName(\u0026#34;t2\u0026#34;); t1.start(); t2.start(); Thread.sleep(20); log.debug(\u0026#34;t2 state: {}\u0026#34;, t2.getState()); Execution result\n2024-01-06 15:36:16 [t2] DEBUG c.w.thread_.commonmethods.Join_ - t2 is waiting for t1 terminating 2024-01-06 15:36:16 [main] DEBUG c.w.thread_.commonmethods.Join_ - t2 state: WAITING 2024-01-06 15:36:16 [t1] DEBUG c.w.thread_.commonmethods.Join_ - t1 terminates 2024-01-06 15:36:16 [t2] DEBUG c.w.thread_.commonmethods.Join_ - t2 terminates interrupt() # The interrupt() method is used to signal a thread that it should interrupt its current operation. This method is part of the Thread class. When interrupt() is called on a thread:\nIf the thread is executing a blocking operation (like sleep(), wait(), or join()), it immediately throws an InterruptedException, which can be caught and handled. This exception CLEARS the interrupted status of the thread. If the thread is NOT in a blocking operation, it doesn\u0026rsquo;t immediately cause an effect other than setting the thread\u0026rsquo;s interrupted status. Example # Interrupt a blocking operation\nThread t1 = new Thread(() -\u0026gt; { try { Thread.sleep(1000); } catch (InterruptedException e) { log.debug(\u0026#34;t1 is interrupted {}\u0026#34;, Thread.currentThread().isInterrupted()); } }, \u0026#34;t1\u0026#34;); t1.start(); Thread.sleep(50); log.debug(\u0026#34;t1 is interrupted {}\u0026#34;, t1.isInterrupted()); t1.interrupt(); log.debug(\u0026#34;t1 is interrupted {}\u0026#34;, t1.isInterrupted()); 2024-01-06 21:58:27 [main] DEBUG c.w.t.c.InterruptBlockedThread - t1 is interrupted false 2024-01-06 21:58:27 [main] DEBUG c.w.t.c.InterruptBlockedThread - t1 is interrupted true 2024-01-06 21:58:27 [t1] DEBUG c.w.t.c.InterruptBlockedThread - t1 is interrupted false Before interrupting t1 thread, its interrupted status is false After invoking interrupt() method, the interrupted status is set to true immediately Thread t1 is interrupted while it is sleeping, and the interruption throws InterruptedException. The exception clears the interrupted status Interrupt a running operation\nThread t1 = new Thread(() -\u0026gt; { while(true) { if (Thread.currentThread().isInterrupted()) { break; } } }, \u0026#34;t1\u0026#34;); t1.start(); Thread.sleep(50); log.debug(\u0026#34;t1 is interrupted {}\u0026#34;, t1.isInterrupted()); t1.interrupt(); log.debug(\u0026#34;t1 is interrupted {}\u0026#34;, t1.isInterrupted()); 2024-01-06 22:02:18 [main] DEBUG c.w.t.c.InterruptRunningThread - t1 is interrupted false 2024-01-06 22:02:18 [main] DEBUG c.w.t.c.InterruptRunningThread - t1 is interrupted true If a thread is interrupted while it is running an operation. Only interrupted status is set to true. Hence interrupt() method is a polite way to signal the thread to stop, and still give the thread to handle some logic and clear some resources before terminating the thread Gracefully Terminate Threads # Code\n@Slf4j public class GracefullyTerminateThread { Thread thread; public GracefullyTerminateThread() {} public void start() { thread = new Thread(() -\u0026gt; { while(!Thread.currentThread().isInterrupted()) { try { log.debug(\u0026#34;Hello World\u0026#34;); Thread.sleep(1000); } catch (InterruptedException e) { log.debug(\u0026#34;Interrupt sleep\u0026#34;); Thread.currentThread().interrupt(); } } log.debug(\u0026#34;Thread gracefully terminates\u0026#34;); }); thread.start(); } public void gracefullyStop() { if (thread != null) { thread.interrupt(); } } } Flowchart\nThe thread continuously performs its task (logging and sleeping) in a loop, constantly checking for an interrupt signal. When gracefullyStop() is called from outside (another thread or method), it signals the thread to stop by setting its interrupted status. Upon receiving the interrupt signal, the thread exits its normal operation, performs any necessary clean-up, and then terminates. Execution\nTest code\npublic class GracefullyTerminate { public static void main(String[] args) throws InterruptedException { GracefullyTerminateThread thread = new GracefullyTerminateThread(); thread.start(); Thread.sleep(3000); thread.gracefullyStop(); } } Result\n2024-01-07 14:18:39 [Thread-0] DEBUG c.w.t.c.g.GracefullyTerminateThread - Hello World 2024-01-07 14:18:40 [Thread-0] DEBUG c.w.t.c.g.GracefullyTerminateThread - Hello World 2024-01-07 14:18:41 [Thread-0] DEBUG c.w.t.c.g.GracefullyTerminateThread - Hello World 2024-01-07 14:18:42 [Thread-0] DEBUG c.w.t.c.g.GracefullyTerminateThread - Interrupt sleep 2024-01-07 14:18:42 [Thread-0] DEBUG c.w.t.c.g.GracefullyTerminateThread - Thread gracefully terminates "},{"id":11,"href":"/docs/programming/project/node-js-auth/","title":"Node Js Auth","section":"Project","content":" Introduction # This project is for learning purpose. It is a practice of\nhow to use JWT (Json Web Token) to authenticate user login with Google using OAuth2 Tech Stack # Node.js Express: Quickly start a local host MongoDB/Mongoose: Database to store users @hapi/joi: Package to validate parameters of objects bcryptjs: Hash confidential information including passwords in this project jsonwebtoken: JWT package to sign and verify a auth token axios: Send HTTP requests querystring: Package to parse and assembly query string in HTTP request Reference # Implement JWT using node.js and express: Very nice video which guides me step by step to build this project Google OAuth2 with node.js: Video that explains and implements OAuth2 flow from end to end OAuth 2.0 and OpenID Connect: Plain English explains the evolution of OAuth2 and OpenID Connect What Is JWT? # A JWT (JSON Web Token) is like a compact digital note or a small piece of data that web servers and clients (like your browser or a mobile app) use to communicate secure information. It\u0026rsquo;s like a tiny, encoded message.\nStructure of JWT # A JWT is made up of three parts, each encoded in base64 and separated by dots (.):\nHeader: The header typically consists of two parts: the type of the token, which is JWT, and the signing algorithm being used, such as SHA256 or RSA. Payload: The payload contains information of the identity, like id, isa(issuedAt), and etc\u0026hellip; Signature: This is the secure part of JWT. It is created by taking encoded header, encoded payload, a secret only known by the server, then running it through the signing algorithm mentioned in the header. If the algorithm is Symmetric algorithm (like HS256): The same secret is used for signing and verification Asymmetric algorithm (like RS256): A private key will be used for signing, and a corresponding public key will be used for verification Risk of JWT # Data is Not Encrypted The first two parts of a JWT token are only base64 encoded, but not encrypted, so everyone can decode them and read data directly. Hence, confidential information should not be stored in the payload Susceptible to Theft If a JWT is stolen, it could by used by unauthorized parties to gain access to the system No Revocation Mechanism Once issued, a JWT can\u0026rsquo;t be revoked before it expires Key Management Challenges The security of JWT depends on how secret key is managed by the server. If the secret is not well managed or securely stored, it could lead security vulnerabilities Best Practice # Use HTTPS to prevent interception of tokens. Keep expiration times as short as practical. Avoid storing sensitive data in the token. Implement token refresh mechanisms. Securely manage signing keys. API # Register # Url: /api/user/register Method: POST Request Body { name: string, email: string, password: string } Response Body { userId: string } Business logic Validate parameters in the request body Validate email is not registered in DB Insert a new user in DB Login # Url: /api/user/login Method: POST Request Body { email: string, password: string } Response Header { auth-token: string } Body { token: string } Business logic Verify if email and password match Sign a new JWT and return it Posts # Url: /api/posts Method: GET Request Header { auth-token: string } Response Body { posts: { title: string, description: string } } Business logic Verify the auth-token from request headers Return a hard-coded post object After users login, server signs a JWT to users. By include the JWT in the request headers, server could verify it to determine if user is authenticated (login)\nOAuth2 # What is OAuth2? # OAuth2 is an open standard for access delegation, which is commonly used as the way for internet users to grant a client or application access to their resources under another server without sharing their passwords\nWhy OAuth2? # Secure Delegation of Access: Users often need to grant a third party website or application access to their data on another service (like accessing your google account from a social media app). Sharing credentials for this purpose is highly insecure\nFine Grained Authorization: User may not want to give full access of their all data\nStandardization and Interoperability: With requirements of authentication and authorization from many internet service, a standard way is needed\nReducing Password Fatigue: Users are overwhelmed by the need to create username and password for each single service\nKey Components of OAuth2 # Resource Owner: The user who authorizes an application to access their account Client: The application that wants to access user\u0026rsquo;s account Resource Server: The server hosting user\u0026rsquo;s data Authorization Server: The server that authenticates user and issues access token to the application How OAuth2 works # Authorization Request\nThe client requests authorization to access user\u0026rsquo;s resources. This is usually done through a redirection, where client passes along its identity (client id) and the scope of the access it\u0026rsquo;s requesting User Authenticate and Consent\nThe user is asked to login to the authorization server and to approve the requested access by the client Authorization Grant\nUpon successful authentication and consent, authorization server issues an authorization grant to the client. The authorization grant can be of different type, like an authorization code or an implicit grant, depending on the OAuth flow being used Access Token Request (In case of authorization code grant)\nIf an authorization code is granted, then client exchanges the code for an access token. This is done by sent a request to authorization server\u0026rsquo;s token endpoint where client authenticates itself and presents the authorization code Issuance of Access Token\nThe authorization server authenticates the client validates the authorization grant and if valid issues an access token (and possibly a refresh token) Accessing the Resource\nThe client uses access to token to make a request to the resource server for the protected resources Resource Server Validates Token\nThe resource server validates the token and if valid serves the request Resource Deliver\nThe client receives the protected resources Why OpenID Connect # OAuth2 was originally designed for authorization, but not for authentication. Different companies have their own standards to authenticate users using OAuth2, in other words, OAuth2 is overused for authentication.\nOpenID Connect is an authentication layer built on top of OAuth2. It was developed to address the need for a standardized authentication process.\nHow OpendID Connect works # Authentication Request The client includes openid in the scope of the authorization request. That indicates that the client is requesting an ID token in addition to access token Token Response Access Token: Just like OAuth2, access token is issued by the authorization server. This token grants access to user\u0026rsquo;s resources ID Token: This is unique to OpenID Connect. The ID token is a JWT which contains claims about user\u0026rsquo;s identity and profile Token Validation Upon receiving the tokens, the client must validate the ID tokens to ensure its integrity and authenticity. This involves verifying JWT signature and the claims it contains "},{"id":12,"href":"/docs/programming/aws/message/sns/","title":"Sns","section":"Message","content":" Architecture # Pub-Sub Model # Publisher # Service or application that sends message to SNS Topic. SNS Topic allows multiple message publisher\nSNS Topic # SNS uses topics to logically separate messages into channels\nFanout The Fanout scenario is when a message published to an SNS topic is replicated and pushed to multiple endpoints, such as Kinesis Data Firehose delivery streams, Amazon SQS queues, HTTP(S) endpoints, and Lambda functions. This allows for parallel asynchronous processing.\nFilter Policy After subscribing to an SNS topic, subscribers will receive all messages published by the topic. To receive a subset of messages, a subscriber must assign a filter policy to the topic subscription.\nRetry Policy Retry Policy is a JSON Object which allows SNS Topic to re-publish message to subscribers when message delivery fails\nDLQ You can set up an SQS DLQ (Dead Letter Queue) to receive messages failed to be delivered after all retries\nResource Policy It\u0026rsquo;s a policy attached to SNS Topic which defines WHO (Primary) can do WHAT (Actions) on WHICH resource\nSubscriber # To receive messages from an SNS topic, applications or receives should subscribe to the SNS topic. After subscription, every message sent to the SNS topic will be replicated and pushed to all subscribers\nSNS V.S. SQS # Push V.S. Pull # SNS topics push message to subscribers. SQS queues retain messages, and consumers need to pull messages from the queue\nMessage Retention # An SQS message is stored on the queue for up to 14 days until it is successfully processed by a consumer. SNS does not retain messages so if there are no subscribers for a topic, the message is discarded.\nMessage Duplication # SNS topics duplicate messages and fan out them to all subscribers. Although SQS queues can have multiple consumers, but one message is processed by only one consumer. The message goes back to the queue if consumers doesn\u0026rsquo;t delete the message before invisible timeout runs out\nMessage Processing # SNS only concerns with message delivery. Apart from message delivery, SQS also cares if the message is processed properly by the consumer. The messages are deleted by the consumer after message processing is finished\n"},{"id":13,"href":"/docs/programming/aws/message/sqs/","title":"Sqs","section":"Message","content":" Architecture of SQS System # Three Main Components # Producers\nProducers in above system are the identities who send message to SQS queue\nSQS Queue\nSQS Queue is a buffer that stores messages and decouples producers and consumers in the system\nConsumers\nConsumers are identities in the system poll message from SQS queue\nHow to Use SQS Queue # Producer sends message\nProducer sens message to SQS Queue, and the message will be visible to all consumers\nMessage state - Visible: The message is able to be polled by any consumers. The message is in visible state when Message is sent to the queue and not pulled by any consumers Message is not deleted before the visibility timeout runs out Visibility timeout: The time that a message stays in the queue but is hidden to all consumers. Message is supposed to be polled and processed by only one consumer at a time. Hence, once a consumer polls the message, it should not be visible to all consumers Consumer polls message\nConsumer polls messages (up to 10 in one batch) from the queue and processes the messages. The message will be invisible until 1. Consumer who polls the message completes message processing and deletes the message 2. Or consumer doesn\u0026rsquo;t delete the message before visibility timeout runs out, and the message becomes visible again\nMessage state - Invisible: The message can\u0026rsquo;t be polled by any consumers. Consumer deletes message\nConsumer completes message processing and deletes the message from the queue\nSQS Encryption # SQS Access Policy # Policy that is attached to a SQS queue, defines WHO (the identity) can perform WHAT actions (APIs that are allowed) on this SQS queue\nCross Account Access Policy # { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;AWS\u0026#34;: \u0026#34;arn:aws:iam::\u0026lt;Account-B-ID\u0026gt;:root\u0026#34; }, \u0026#34;Action\u0026#34;: [ \u0026#34;SQS:SendMessage\u0026#34;, \u0026#34;SQS:ReceiveMessage\u0026#34;, \u0026#34;SQS:DeleteMessage\u0026#34;, \u0026#34;SQS:GetQueueAttributes\u0026#34;, \u0026#34;SQS:GetQueueUrl\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sqs:\u0026lt;region\u0026gt;:\u0026lt;Account-A-ID\u0026gt;:\u0026lt;queue-name\u0026gt;\u0026#34; } ] } The access policy allows Account-B to access SQS queue in Account-A SQS Standard Queue # Attributes # Unlimited throughput and number of messages in queue Default retention of message: 4 days. Max: 14 days Low latency Limitation of 256¬†KB per message Can have duplicate messages Could be out of order DLQ (Dead Letter Queue) # If consumer doesn\u0026rsquo;t delete the message from the queue before visibility timeout runs out, the message will be visible again and receive count for that message increments.\nWe can set up a threshold of how many times a message could go back to the queue. If MaximumReceives threshold is exceeded, the message goes into a dead letter queue\nDLQ is mainly for debugging purpose. It also supports to re-drive failing messages which sends messages from DLQ to SQS queue\n"},{"id":14,"href":"/docs/programming/web/security/tls-handshake/","title":"TLS Handshake","section":"Security","content":" TLS/SSL and HTTPS # TLS (Transport Layer Security) and its predecessor, SSL (Secure Sockets Layer), are integral to HTTPS, which stands for Hypertext Transfer Protocol Secure. HTTPS is the secure version of HTTP, the primary protocol used for transmitting web pages over the internet. This post will introduce the process of TLS handshake, and the TLS version is TLS 1.2\nTLS Handshake # Client to Server: ClientHello\nThe client starts the handshake by sending a ClientHello message. This message includes\nthe TLS version the client supports, a list of cryptographic algorithms (cipher suites) it can use, and a random byte string (client random) for key generation purposes. Server to Client: ServerHello The server responds with a ServerHello message. This message indicates the chosen TLS protocol version (compatible with the client\u0026rsquo;s version), selects a cipher suite from the client\u0026rsquo;s list, and includes a server-generated random byte string (server random).\nServer to Client: Certificate The server sends its digital certificate to the client. This certificate, typically issued by a trusted Certificate Authority (CA), contains the server\u0026rsquo;s public key and is used to authenticate the server to the client.\nServer to Client: Server Key Exchange This message is sent by the server only if the server\u0026rsquo;s digital certificate does not contain enough data to allow the client to exchange a pre-master secret. It provides cryptographic parameters necessary for the client to establish the pre-master secret.\nServer to Client: Server Hello Done This message indicates the end of the ServerHello and associated messages. After sending this message, the server waits for the client\u0026rsquo;s response.\nClient to Server: Client Key Exchange, Change Cipher Spec, Encrypted Handshake Message\nClient Key Exchange: The client responds with key exchange data, which typically includes a pre-master secret encrypted with the server\u0026rsquo;s public key. Change Cipher Spec: The client then sends a message indicating that subsequent messages from the client will be encrypted using the newly agreed cipher suite and keys. Encrypted Handshake Message: This is a \u0026lsquo;Finished\u0026rsquo; message encrypted with the new encryption settings. It provides a cryptographic check that ensures the integrity of the handshake thus far. 7. Server to Client: Encrypted Handshake Message\nThe server decrypts the client\u0026rsquo;s \u0026lsquo;Finished\u0026rsquo; message and verifies it. Then, it sends its own \u0026lsquo;Finished\u0026rsquo; message, encrypted with the agreed cipher suite and keys. This message serves to confirm that the server part of the handshake is complete and that the server will begin to use the new security settings for all subsequent messages.\nSymmetric Encryption in TLS Handshake # Establishing a Session Key: After the asymmetric exchange of the pre-master secret, both the client and the server independently compute the master secret from the pre-master secret and the random numbers exchanged in the ClientHello and ServerHello messages.\nGeneration of Session Keys: From the master secret, both parties derive a set of symmetric session keys using a secure key derivation function. These keys include separate encryption and MAC (Message Authentication Code) keys for both client-to-server and server-to-client communication.\nData Encryption: Once the symmetric session keys are established, all subsequent data transmitted during the TLS session is encrypted using symmetric encryption. This includes the final part of the handshake, where both the client and server exchange \u0026lsquo;Finished\u0026rsquo; messages encrypted with the symmetric keys.\nReference # Bilibili Video\n"},{"id":15,"href":"/docs/programming/backend/java/thread/thread-lifecycle/","title":"Thread Lifecycle","section":"Thread","content":" Six Java Thread States # NEW State:\nWhen you create an instance of a Thread class (or a class that extends Thread), the thread is in the New state. At this point, the thread is not yet running. Example: Thread t = new Thread(); RUNNABLE State:\nWhen you invoke the start() method, the thread moves to the RUNNABLE state In a typical implementation, a Java thread in the RUNNABLE state corresponds to an OS thread that is eligible for running A RUNNABLE state means the thread is either running on the CPU or waiting for Scheduler to allocate CPU resource BLOCKED State:\nA thread enters the BLOCKED state when it tries to acquire a monitor lock (intrinsic lock) of an object but another thread already holds that lock. This commonly occurs in synchronized blocks or methods. WAITING State:\nA thread is in the WAITING state when it is waiting for another thread to perform a specific action. Unlike the BLOCKED state, where a thread is waiting to acquire a lock, in the WAITING state, a thread is waiting for another thread\u0026rsquo;s action without any lock competition How WAITING state occurs Object.wait() WITHOUT timeout Thread.join() WITHOUT timeout TIMED_WAITING State:\nA thread is in this state when it is waiting for another thread to perform an action for up to a specified waiting time. After the time expires, the thread will automatically return to the RUNNABLE state if it\u0026rsquo;s not blocked by other means How TIMED_WAITING state occurs Thread.sleep(long millis) Object.wait WITH timeout Thread.join WITH timeout TERMINATED State:\nA thread enters the TERMINATED state when it completes the execution of its run() method or if an exception occurs. Once terminated, a thread cannot be restarted. State Transition # Demo # Code\n@Slf4j public class SixStates { public static void main(String[] args) { Thread newThread = new Thread(() -\u0026gt; { log.debug(\u0026#34;Start a new thread\u0026#34;); }, \u0026#34;NEW-thread\u0026#34;); Thread runnableThread = new Thread(() -\u0026gt; { while(true) { } }, \u0026#34;RUNNABLE-thread\u0026#34;); runnableThread.start(); Thread timedWaitingThread = new Thread(() -\u0026gt; { try { Thread.sleep(1_000_000); } catch (InterruptedException e) { throw new RuntimeException(e); } }, \u0026#34;TIMED_WAITING-thread\u0026#34;); timedWaitingThread.start(); Thread waitingThread = new Thread(() -\u0026gt; { try { synchronized (SixStates.class) { runnableThread.join(); } } catch (InterruptedException e) { throw new RuntimeException(e); } }, \u0026#34;WAITING-thread\u0026#34;); waitingThread.start(); Thread blockedThread = new Thread(() -\u0026gt; { synchronized (SixStates.class) { log.debug(\u0026#34;BLOCKED thread\u0026#34;); } }, \u0026#34;BLOCKED-thread\u0026#34;); blockedThread.start(); Thread terminatedThread = new Thread(() -\u0026gt; { }, \u0026#34;TERMINATED-thread\u0026#34;); terminatedThread.start(); log.debug(\u0026#34;{}\u0026#34;, newThread.getState()); log.debug(\u0026#34;{}\u0026#34;, runnableThread.getState()); log.debug(\u0026#34;{}\u0026#34;, timedWaitingThread.getState()); log.debug(\u0026#34;{}\u0026#34;, waitingThread.getState()); log.debug(\u0026#34;{}\u0026#34;, blockedThread.getState()); log.debug(\u0026#34;{}\u0026#34;, terminatedThread.getState()); } } Execution 2024-01-07 14:57:44 [main] DEBUG c.w.thread_.lifecycle.SixStates - NEW 2024-01-07 14:57:44 [main] DEBUG c.w.thread_.lifecycle.SixStates - RUNNABLE 2024-01-07 14:57:44 [main] DEBUG c.w.thread_.lifecycle.SixStates - TIMED_WAITING 2024-01-07 14:57:44 [main] DEBUG c.w.thread_.lifecycle.SixStates - WAITING 2024-01-07 14:57:44 [main] DEBUG c.w.thread_.lifecycle.SixStates - BLOCKED 2024-01-07 14:57:44 [main] DEBUG c.w.thread_.lifecycle.SixStates - TERMINATED "},{"id":16,"href":"/docs/programming/backend/java/netty/pipeline-handler/","title":"Pipeline \u0026 Handler","section":"Netty","content":" Handler # Role # A Handler in Netty is a component that contains the business logic for processing inbound and outbound data as well as various network (channel) events.\nTypes # ChannelInboundHandler:\nPurpose: Deals with inbound data and events. It processes incoming data and reacts to channel events Key Methods: channelRead, channelActive, channelInactive, channelRegistered, channelUnregistered. Usage: You override these methods to perform actions like reading data from a network socket, reacting to channel activation or deactivation, etc. ChannelOutboundHandler:\nPurpose: Responsible for handling outbound operations, such as writing data to the network or closing the channel. Key Methods: write, flush, close, bind, connect. Usage: These methods are overridden to intercept and execute operations that modify the state of the channel or write data to it. Pipeline # What is pipeline? # A Netty pipeline is an ordered list of handlers. It represents a sequence of operations that are applied to inbound and outbound data.\nStructure and Flow # ChannelPipeline: Each Channel in Netty has its own ChannelPipeline. This pipeline is automatically created when the channel is created. Ordered Sequence: Handlers are placed in the pipeline in a specific order, and the data or events are processed in this sequence. Data Flow: Inbound Data: Flows head-to-tail through the pipeline. Each inbound handler processes the data and passes it to the next handler. Outbound Data: Flows tail-to-head. Each outbound handler processes the data and passes it back towards the head of the pipeline. Example # Server # 1. EventLoopGroup boss = new NioEventLoopGroup(); 2. EventLoopGroup worker = new NioEventLoopGroup(2); 3. ChannelInboundHandlerAdapter inboundHandler1 = new ChannelInboundHandlerAdapter() { 4. @Override 5. public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { 6. ByteBuf buf = (ByteBuf) msg; 7. String message = buf.toString(StandardCharsets.UTF_8); 8. log.debug(\u0026#34;InboundHandler_1 receives msg: [{}]\u0026#34;, message); 9. super.channelRead(ctx, message); 10. } 11. }; 12. ChannelInboundHandlerAdapter inboundHandler2 = new ChannelInboundHandlerAdapter() { 13. @Override 14. public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { 15. log.debug(\u0026#34;InboundHandler_2 receives msg: [{}]\u0026#34;, msg); 16. ctx.channel().writeAndFlush(ctx.alloc().buffer().writeBytes(\u0026#34;Hello Client\u0026#34;.getBytes())); 17. super.channelRead(ctx, msg); 18. } 19. }; 20. ChannelOutboundHandlerAdapter outboundHandler1 = new ChannelOutboundHandlerAdapter() { 21. @Override 22. public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { 23. log.debug(\u0026#34;OutboundHandler_1 writes msg\u0026#34;); 24. super.write(ctx, msg, promise); 25. } 26. }; 27. ChannelOutboundHandlerAdapter outboundHandler2 = new ChannelOutboundHandlerAdapter() { 28. @Override 29. public void write(ChannelHandlerContext ctx, Object msg, ChannelPromise promise) throws Exception { 30. log.debug(\u0026#34;OutboundHandler_2 writes msg\u0026#34;); 31. super.write(ctx, msg, promise); 32. } 33. }; 34. new ServerBootstrap() 35. .group(boss, worker) 36. .channel(NioServerSocketChannel.class) 37. .childHandler(new ChannelInitializer\u0026lt;NioSocketChannel\u0026gt;() { 38. @Override 39. protected void initChannel(NioSocketChannel nioSocketChannel){ 40. ChannelPipeline pipeline = nioSocketChannel.pipeline(); 41. nioSocketChannel.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); 42. pipeline.addLast(inboundHandler1); 43. pipeline.addLast(inboundHandler2); 44. pipeline.addLast(outboundHandler1); 45. pipeline.addLast(outboundHandler2); 46. } 47. }) 48. .bind(9999); Line 1-2. EventLoopGroups Creation: Two EventLoopGroup instances are created. boss handles accepting new connections, and worker (with 2 threads) handles actual I/O operations for the connections. Line 3-11. First Inbound Handler: A custom inbound handler (inboundHandler1) that reads incoming data (as ByteBuf), converts it to a string, logs it, and forwards it down the pipeline. Line 12-19. Second Inbound Handler: Another inbound handler (inboundHandler2) that logs the received message and writes a response back to the client. Line 20-26. First Outbound Handler: A custom outbound handler (outboundHandler1) that logs a debug message when it writes data. Line 27-33. Second Outbound Handler: Another outbound handler (outboundHandler2) with similar functionality as the first outbound handler, logging when data is written. 34-48. Bootstrap a server. In the channel pipeline, five handlers are added, including a logging handler and the two inbound and two outbound handlers Client # EventLoopGroup group = new NioEventLoopGroup(); ChannelFuture channelFuture = new Bootstrap() .group(group) .channel(NioSocketChannel.class) .handler(new ChannelInitializer\u0026lt;NioSocketChannel\u0026gt;() { @Override protected void initChannel(NioSocketChannel nioSocketChannel) { nioSocketChannel.pipeline().addLast(new LoggingHandler(LogLevel.DEBUG)); nioSocketChannel.pipeline().addLast(new StringEncoder()); } }) .connect(new InetSocketAddress(\u0026#34;localhost\u0026#34;, 9999)); Channel channel = channelFuture.sync().channel(); channel.writeAndFlush(\u0026#34;Hello World\u0026#34;); Client connects to the server Then client sends a message to the server Execution # Start the server Start the client Execution Result # Server log\n2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x9ce2b880, L:/127.0.0.1:9999 - R:/127.0.0.1:46006] REGISTERED 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x9ce2b880, L:/127.0.0.1:9999 - R:/127.0.0.1:46006] ACTIVE 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x9ce2b880, L:/127.0.0.1:9999 - R:/127.0.0.1:46006] READ: 11B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 48 65 6c 6c 6f 20 57 6f 72 6c 64 |Hello World | +--------+-------------------------------------------------+----------------+ 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG c.w.n.c.pipeline_handler.Server - InboundHandler_1 receives msg: [Hello World] 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG c.w.n.c.pipeline_handler.Server - InboundHandler_2 receives msg: [Hello World] 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG c.w.n.c.pipeline_handler.Server - OutboundHandler_2 writes msg 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG c.w.n.c.pipeline_handler.Server - OutboundHandler_1 writes msg 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x9ce2b880, L:/127.0.0.1:9999 - R:/127.0.0.1:46006] WRITE: 12B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 48 65 6c 6c 6f 20 43 6c 69 65 6e 74 |Hello Client | +--------+-------------------------------------------------+----------------+ 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x9ce2b880, L:/127.0.0.1:9999 - R:/127.0.0.1:46006] FLUSH 2024-01-03 22:16:03 [nioEventLoopGroup-3-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0x9ce2b880, L:/127.0.0.1:9999 - R:/127.0.0.1:46006] READ COMPLETE Client log\n2024-01-03 22:16:03 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xa3ce2712] REGISTERED 2024-01-03 22:16:03 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xa3ce2712] CONNECT: localhost/127.0.0.1:9999 2024-01-03 22:16:03 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xa3ce2712, L:/127.0.0.1:46006 - R:localhost/127.0.0.1:9999] ACTIVE 2024-01-03 22:16:03 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xa3ce2712, L:/127.0.0.1:46006 - R:localhost/127.0.0.1:9999] WRITE: 11B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 48 65 6c 6c 6f 20 57 6f 72 6c 64 |Hello World | +--------+-------------------------------------------------+----------------+ 2024-01-03 22:16:03 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xa3ce2712, L:/127.0.0.1:46006 - R:localhost/127.0.0.1:9999] FLUSH 2024-01-03 22:16:03 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xa3ce2712, L:/127.0.0.1:46006 - R:localhost/127.0.0.1:9999] READ: 12B +-------------------------------------------------+ | 0 1 2 3 4 5 6 7 8 9 a b c d e f | +--------+-------------------------------------------------+----------------+ |00000000| 48 65 6c 6c 6f 20 43 6c 69 65 6e 74 |Hello Client | +--------+-------------------------------------------------+----------------+ 2024-01-03 22:16:03 [nioEventLoopGroup-2-1] DEBUG i.n.handler.logging.LoggingHandler - [id: 0xa3ce2712, L:/127.0.0.1:46006 - R:localhost/127.0.0.1:9999] READ COMPLETE Pipeline Virtualization # Double-Linked List:\nEach handler in the pipeline is a node in a double-linked list, maintaining references to its previous and next handlers. This allows for efficient traversal in both directions ‚Äì towards the head for outbound events and towards the tail for inbound events. Dynamic Modification:\nThe double-linked list structure allows for handlers to be dynamically added, removed, or replaced at runtime. This is crucial for Netty\u0026rsquo;s flexibility, enabling the pipeline to adapt to different protocol requirements or runtime conditions. Ordered Processing:\nThe order of handlers in the list determines the order of processing. Inbound data flows through the pipeline from the first (head) to the last (tail) handler, while outbound data flows in the opposite direction. Contextual Linkage:\nEach handler is associated with a ChannelHandlerContext, which provides the handler with its position (context) in the pipeline. This context is used to interact with the pipeline, such as forwarding events, accessing the channel, or modifying the pipeline itself. Head and Tail Contexts:\nSpecial HeadContext and TailContext nodes are typically present in the beginning and at the ends of the pipeline. These nodes handle some standard operations, like the initial entry of events into the pipeline or the termination of event propagation. How Does It Work? # Client\nClient Registration, Connection, and Activation The client registers a new channel (REGISTERED), connects to the server (CONNECT), and becomes active (ACTIVE). Server\nServer Registration and Activation The server registers a new channel (REGISTERED) and then becomes active (ACTIVE). This indicates that the server accepts client\u0026rsquo;s connection Client\nSending Data to Server: The client writes (WRITE) the \u0026ldquo;Hello World\u0026rdquo; message (11 bytes) and then flushes it (FLUSH) to the server. Server\nReceiving Client Data:\nThe server reads (READ) 11 bytes of data from the client. This data corresponds to the string \u0026ldquo;Hello World\u0026rdquo;. Inbound Handler Processing:\nInboundHandler_1 on the server receives the \u0026ldquo;Hello World\u0026rdquo; message, logs it, and passes it along. InboundHandler_2 also receives the \u0026ldquo;Hello World\u0026rdquo; message, logs it, and then writes a response (\u0026ldquo;Hello Client\u0026rdquo;) back to the client. Outbound Handler Processing:\nOutboundHandler_2 and OutboundHandler_1 log the message as it passes through the outbound pipeline. The server then writes 12 bytes, which is the \u0026ldquo;Hello Client\u0026rdquo; response, and flushes it (FLUSH) to the client. Completion of Read Operation:\nThe READ COMPLETE event signifies the end of the read operation for this round of communication. Client\nReceiving Server Response: The client reads (READ) 12 bytes of data, which is the \u0026ldquo;Hello Client\u0026rdquo; message sent by the server. Completion of Read Operation: Similar to the server, the READ COMPLETE event on the client side indicates the end of the read operation. "},{"id":17,"href":"/docs/programming/web/security/session-vs-token/","title":"Session vs Token","section":"Security","content":" Introduction # Both sessions and tokens are used for user authentication and maintaining user state across multiple HTTP requests in a web application.\nProcess # Session-Based Authentication Process # 1-2: User Login Attempt\nThe user submits their login credentials (usually username and password) through the client (e.g., a web browser). 3-4: Credentials Verification\nThe server receives the credentials and verifies them against its user database or authentication source. 5-6: Session Creation\nUpon successful verification, the server creates a new session. This session is stored in the server\u0026rsquo;s memory or a session store (like a database). 7: Sending Session ID to Client\nThe server sends this session ID back to the client, typically as a cookie. This cookie is stored in the user\u0026rsquo;s browser. Client Stores Session ID\nThe browser stores this session ID and sends it along with every subsequent request to the server. Server Session Validation\nFor each new request from the client, the server reads the session ID from the cookie, looks up the corresponding session in its session store, and validates it. Token-Based Authentication Process (Using JWT) # 1-2: User Login Attempt\nThe user submits their login credentials (usually username and password) through the client (e.g., a web browser). 3-4: Credentials Verification\nThe server receives the credentials and verifies them against its user database or authentication source. Token Generation\nUpon successful verification, the server generates a token (like a JWT). This token includes encoded user information and is digitally signed by the server. 5: Server sends Token to Client\n6: Client Stores Token\nToken Sent with Requests\nFor every subsequent request, the client attaches this token, typically in the HTTP Authorization header. Server Token Validation\nThe server validates the token on each request. This involves verifying the token‚Äôs integrity and possibly checking against a list of revoked tokens. Comparison # Session-Based Authentication # User Information Storage:\nIn session-based authentication, user information is stored on the server. This can include user identity, authentication status, user preferences, and other session-related data. Server Memory and Resources:\nSince the data is stored server-side, it consumes server memory and resources. This can be significant, especially with a large number of concurrent users. Client-Server Interaction:\nDuring subsequent requests, the client sends this session ID back to the server. The server uses this ID to retrieve the user\u0026rsquo;s session information and authenticate the request. Security:\nThe actual user data is not exposed to the client, which can be a security advantage. However, the session ID needs to be protected to prevent session hijacking. Scalability Concerns:\nStoring session data for each user can impact the scalability of the application, especially in distributed systems where session data might need to be shared across servers. Token-Based Authentication (e.g., JWT) # User Information Storage:\nIn token-based systems like JWT, user authentication information is encoded and optionally encrypted within the token itself. This can include user ID, roles, permissions, and other claims. Client-Side Storage:\nThe token is stored on the client side, typically in the browser\u0026rsquo;s local storage, session storage, or as an HTTP-only cookie. Stateless Operation:\nEach request from the client includes the token, allowing the server to authenticate the request statelessly, without needing to store user session data. Security:\nWhile the user information in the token can be read by the client, sensitive data should never be stored in a token payload unless encrypted. The token is also susceptible to different types of attacks (like XSS), and thus must be handled securely. Scalability and Performance:\nSince the server does not store session state, token-based authentication can be more scalable, reducing the load and memory requirements on the server. "},{"id":18,"href":"/docs/programming/backend/java/nio/unblocking-mode/","title":"Unblocking Mode","section":"Nio","content":" Unblocking Mode # In last post, we discussed blocking mode and its problems. In this post, we will discuss unblocking mode and its problems\nCode Example # Server\n@Slf4j public class Server { public static void main(String[] args) throws IOException { ByteBuffer buffer = ByteBuffer.allocate(32); ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.bind(new InetSocketAddress(9999)); ssc.configureBlocking(false); List\u0026lt;SocketChannel\u0026gt; channels = new ArrayList\u0026lt;\u0026gt;(); while (true) { log.debug(\u0026#34;Server connecting\u0026#34;); SocketChannel sc = ssc.accept(); if (sc != null) { log.debug(\u0026#34;Connect to client \u0026#34; + sc.getRemoteAddress()); sc.configureBlocking(false); channels.add(sc); } for (SocketChannel channel : channels) { log.debug(\u0026#34;Server reading\u0026#34;); int read = channel.read(buffer); if (read != 0) { buffer.flip(); ByteBufferReader.readAll(buffer); buffer.clear(); log.debug(\u0026#34;Read data from client \u0026#34; + channel.getRemoteAddress()); } } } } } Comparing with server code of blocking mode, we set blocking configuration of the ServerSocketChannel and SocketChannel to false ssc.configureBlocking(false); sc.configureBlocking(false); Also we add a conditional check before adding the SocketChannel to the list and reading data from the channel. That is because in unblocking mode, method scc.accept() will not be blocked, instead it returns a SocketChannel object or null depending on if a client connects to the server. Hence, we should only add the SocketChannel to the list if it is not null, in other words, a client connects to the server. Method channel.read(buffer) will always read from the Channel no matter clients send data or not. What the method returns is the length of bytes it reads. Here we only handle the data if len \u0026gt; 0 if (sc != null) { ... } if (read != 0) { ... } Client\n@Slf4j public class Client { public static void main(String[] args) throws IOException { SocketChannel sc = SocketChannel.open(); log.debug(\u0026#34;Connecting to server\u0026#34;); sc.connect(new InetSocketAddress(InetAddress.getLocalHost(), 9999)); log.debug(\u0026#34;Connected with server\u0026#34;); while (true) { String input = Scanner_.scanLine(\u0026#34;Input: \u0026#34;); log.debug(\u0026#34;Sending data [{}] to server\u0026#34;, input); sc.write(StandardCharsets.UTF_8.encode(input)); log.debug(\u0026#34;Sent data [{}] to server\u0026#34;, input); } } } Client code has no difference with that code in blocking mode Demo # Start the server # Server log:\n... 09:26:19.287 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server connecting 09:26:19.287 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server connecting 09:26:19.287 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server connecting 09:26:19.287 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server connecting ... The log Server connecting is printed infinitely because of unblocking mode Client connects to the server # Server log:\n... 09:28:40.194 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server connecting 09:28:40.194 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server reading 09:28:40.194 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server connecting 09:28:40.194 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server reading 09:28:40.194 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Server connecting ... Logs are continuously printed, but this time, new log Server Reading is printed also because after the client connects to the server, the SocketChannel is added in the list, and the server unblockingly reads the channel Client log:\n09:28:33.989 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Connecting to server 09:28:33.993 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Connected with server Input: Client sends data to the server # To better demonstrate unblocking mode, I removed some logs in the server code to avoid logs from continuously being printed. Then I restarted the server, and connects to the client\nClient log:\n09:40:28.973 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Connecting to server 09:40:28.976 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Connected with server Input: Hello Server from ClientA! 09:40:45.721 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Sending data [Hello Server from ClientA!] to server 09:40:45.722 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Sent data [Hello Server from ClientA!] to server Input: Hello Server from ClientA Again! 09:40:57.604 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Sending data [Hello Server from ClientA Again!] to server 09:40:57.605 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Client - Sent data [Hello Server from ClientA Again!] to server Input: A client connects to the server and sends two strings to the server. In blocking mode, the server should only receive first string and receive second string until another client connects to the server Server log\n09:40:28.989 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Connect to client /127.0.0.1:50930 09:40:45.723 [main] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello Server from ClientA! 09:40:45.723 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Read data from client /127.0.0.1:50930 09:40:57.605 [main] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello Server from ClientA Again! 09:40:57.605 [main] DEBUG com.whatsbehind.netty_.nio.nonblocking.Server - Read data from client /127.0.0.1:50930 The server connects to the client Further more, it receives all strings from the client. As we can see here, because the server is running in unblocking mode, it can handle client connection and data communication concurrently Summary # In unblocking mode, the blocking methods get executed, so the server can handle multiple connections and receive data from multiple clients concurrently. However, different from blocking mode in which the CPU is blocked for most time, CPU in unblocking mode is busy and always running. That\u0026rsquo;s the problem of unblocking mode and it is a waste of resource cause in most time, CPU doesn\u0026rsquo;t do any useful work but run the while loop\u0026hellip; In the next post, we will discuss how NIO uses Selector to handle this issue "},{"id":19,"href":"/docs/programming/backend/java/thread/synchornization/","title":"Synchronization","section":"Thread","content":" Thread Interference # Imagine you have an object that maintains a hit count for a website. If two threads increment the hit counter at the same time, they might read the same value, say 100. Both threads then increment it and set it back to the object. The result should be 102 hits, but because there was no synchronization, you only get 101 - one hit is lost. This is a simple example of a race condition.\npublic class ThreadInterference { public static void main(String[] args) throws InterruptedException { InterferenceThread thread1 = new InterferenceThread(); InterferenceThread thread2 = new InterferenceThread(); thread1.start(); thread2.start(); thread1.join(); thread2.join(); int count = InterferenceThread.getCount(); System.out.println(\u0026#34;The value of count in InterferenceThread class is supposed to be 2_000_000, but the real value is: \u0026#34; + count); } } class InterferenceThread extends Thread { static int count = 0; int loopCount = 0; public static int getCount() { return count; } @Override public void run() { while (loopCount++ \u0026lt; 1_000_000) { count++; } } } /* * Executing result: * The value of count InterferenceThread class is supposed to be 2_000_000, but the real value is: 1563643 * */ Introduction to Synchronization # In Java, synchronization is a mechanism that allows us to control the access of multiple threads to any shared resource. It\u0026rsquo;s critical because it helps prevent thread interference and consistency problems.\nWhy do we need synchronization? # To avoid thread interference which occurs when multiple threads try to access and modify the shared resource concurrently. To prevent consistency problems by making sure that the shared resource is in a consistent state. To achieve thread safety when creating applications that are intended to be used in a multithreaded environment. The Concept of a Monitor (Intrinsic Locks) # Every Java object has an intrinsic lock associated with it. When a thread wants to execute a synchronized method on an object, it first needs to obtain the intrinsic lock. Here\u0026rsquo;s how it works:\nWhen a synchronized method is called, the thread automatically acquires the lock before executing the method. Other threads that attempt to call a synchronized method on the same object are blocked until the first thread exits the method and releases the lock. Synchronized Methods/Block # Synchronized methods allow us to create thread-safe operations by ensuring that only one thread can execute a synchronized method on an instance at a time. When a thread is executing a synchronized method, all other threads that invoke synchronized methods on the same instance will be blocked until the first thread exits the method.\nClass-Level Synchronization # You can synchronize static methods or code snippets containing static fields, which locks the Class object associated with the class. This means it locks at the class level, and only one thread can execute any of the synchronized static methods for that class.\npublic class ClassLevelSynchronization { public static void main(String[] args) throws InterruptedException { ClassLevelSyncThread thread1 = new ClassLevelSyncThread(); ClassLevelSyncThread thread2 = new ClassLevelSyncThread(); thread1.start(); thread2.start(); thread1.join(); thread2.join(); int count = ClassLevelSyncThread.getCount(); System.out.println(\u0026#34;The value of count in InterferenceThread class is supposed to be 2_000_000, but the real value is: \u0026#34; + count); } } class ClassLevelSyncThread extends Thread { static int count = 0; int loopCount = 0; public static int getCount() { return count; } @Override public void run() { while (loopCount++ \u0026lt; 1_000_000) { synchronized (ClassLevelSyncThread.class) { count++; } } } } /* * The value of count in InterferenceThread class is supposed to be 2_000_000, but the real value is: 2000000 * */ In above example, code count++ is wrapped by a synchronized block, and the lock for this block is SynchronizedThread.class, which means at any time only one SynchronizedThread thread can execute count++ code.\nWhy use SynchronizedThread.class as the lock? That is because count is a static field, and its value is associated to SynchronizedThread class instead of any concrete objects. If we use a concrete object as the lock like this, cause the lock belongs to different objects, the scenario that multiple threads access the same variable at a moment will happen again. You can replace the SynchronizedThread.class with this and check the executing results.\nInstance-Level Synchronization # When you synchronize an instance method, you are locking the instance for which the method was called. Only one thread per instance can execute any of the synchronized instance methods.\npublic class InstanceLevelSynchronization { public static void main(String[] args) throws InterruptedException { InstanceLevelSyncThread instanceLevelSyncThread = new InstanceLevelSyncThread(); Thread thread1 = new Thread(instanceLevelSyncThread); Thread thread2 = new Thread(instanceLevelSyncThread); Thread thread3 = new Thread(instanceLevelSyncThread); thread1.start(); thread2.start(); thread3.start(); thread1.join(); thread2.join(); thread3.join(); int count = instanceLevelSyncThread.getCount(); System.out.println(\u0026#34;The value of count in InterferenceThread class is supposed to be 3_000_000, but the real value is: \u0026#34; + count); } } class InstanceLevelSyncThread implements Runnable { int count = 0; @Override public void run() { for (int loopCount = 0; loopCount \u0026lt; 1_000_000; loopCount++) { synchronized (this) { count++; } } } public int getCount() { return count; } } /* * Executing results: * The value of count in InterferenceThread class is supposed to be 3_000_000, but the real value is: 3000000 * */ Here we initiate a InstanceLevelSyncThread instance and create three threads with the instance passed in. The lock for the synchronized block here is this, which is the instance we create.\nWe craete three threads, why are they synchronized by InstanceLevelSyncThread instance?\n/* What will be run. */ private Runnable target; public Thread(Runnable target) { this(null, target, \u0026#34;Thread-\u0026#34; + nextThreadNum(), 0); } @Override public void run() { if (target != null) { target.run(); } } Let\u0026rsquo;s first look at the source code of Thread. Thread has a Runnable filed target and a constructor taking Runnable instance as parameter. Look at the run() method in Thread, the code what will be run is not the Thread itself but the Runnable instance target. In above example, alother we create three Thread instance, but we pass same target to them, so the codes run by each thread are all from same instance, which is target. That\u0026rsquo;s why, count is synchronized by this.\nWhy do we use for loop here, any problem using while loop with loopCount? loopCount is a instance-level variable which is a shared field to different threads. If we use a while loop with loopCount like below, cause it is not synchronized, its value could be implemented by different threads at same moment. In other words, loopCount is not thread safe.\nwhile (loopCount++ \u0026lt; 1_000_000) { synchronized (this) { count++; } } However, when using a for loop, we create a new int varibale each time when run() method is executed, which won\u0026rsquo;t be shared by multiple threads, so it is thread safe.\nfor (int loopCount = 0; loopCount \u0026lt; 1_000_000; loopCount++) { synchronized (this) { count++; } } "},{"id":20,"href":"/docs/programming/backend/java/nio/selector/","title":"Selector","section":"Nio","content":" Selector in Java NIO # A Selector in Java NIO is a special type of object that can check one or more NIO channels and determine which channels are ready for data operations (such as reading or writing). This is crucial in scenarios like servers handling multiple client connections.\nKey Features: # Multiplexing: A single selector can handle multiple channels. Non-blocking Mode: Channels registered with a selector are usually in non-blocking mode. Efficiency: Instead of using multiple threads to handle channels, one thread can handle multiple channels using a selector. How Selectors Work: # Create a Selector: Obtain a selector using the Selector.open() method. Register Channels with Selector: Channels (like SocketChannel) need to be registered with the selector. Selection: Use the select() method to check which channels are ready. This method blocks until at least one channel is ready. Below is the code example of server. Let\u0026rsquo;s read the code line by line to understand how selector works\n@Slf4j public class Server { public static void main(String[] args) throws IOException { Selector selector = Selector.open(); log.debug(\u0026#34;Create a selector\u0026#34;); ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.bind(new InetSocketAddress(9999)); ssc.configureBlocking(false); ssc.register(selector, SelectionKey.OP_ACCEPT, null); log.debug(\u0026#34;Register ServerSocketChannel under selector\u0026#34;); while (true) { log.debug(\u0026#34;Start selecting\u0026#34;); selector.select(); log.debug(\u0026#34;Selected\u0026#34;); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = selector.selectedKeys().iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); ServerSocketChannel channel = (ServerSocketChannel) key.channel(); SocketChannel sc = channel.accept(); log.debug(\u0026#34;Connected to client {}\u0026#34;, sc.getRemoteAddress()); } } } } Create a Selector\nSelector selector = Selector.open(); Here we create a new Selector which has two important collections, keys and selectedKeys. At this time, the two collections are still empty. Let\u0026rsquo;s go ahead to understand what those two collection hold Register a channel with the selector\nServerSocketChannel ssc = ServerSocketChannel.open(); ssc.bind(new InetSocketAddress(9999)); ssc.configureBlocking(false); ssc.register(selector, SelectionKey.OP_ACCEPT, null); We create a new ServerSocketChannel Then register the ServerSocketChannel under the selector In register method, we pass in the selector and interested operation. For the ServerSocketChannel, it only interests in ACCEPT operation. We will introduce more operations later After registration, a new SelectionKey is created and added into collection keys Select channels with event\nselector.select(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = selector.selectedKeys().iterator(); After invoking select method, the selector will monitor all registered channels. The method will be blocked here until channels have event Once channels have event happened, the selector will add those channels to another collection selectedKeys Handle channel operations\nSelectionKey key = keyIterator.next(); ServerSocketChannel channel = (ServerSocketChannel) key.channel(); SocketChannel sc = channel.accept(); Only one channel is registered under the selector, so I cast the channel to ServerSocketChannel and let it accept client\u0026rsquo;s connection Demo # Start the server\n08:45:22.261 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Create a selector 08:45:22.268 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Register ServerSocketChannel under selector 08:45:22.268 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Start selecting The selector starts to monitor registered channels. select method is blocked until event happens in the channel ClientA connects\n08:46:01.420 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 08:46:01.421 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Connected to client /127.0.0.1:47074 08:46:01.422 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Start selecting ClientB connects\n08:46:31.762 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 08:46:31.762 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Connected to client /127.0.0.1:47080 08:46:31.762 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Start selecting "},{"id":21,"href":"/docs/programming/backend/java/nio/selector-read/","title":"Selector Read","section":"Nio","content":" Read Operation in Selector # In last post, we discussed Selector and how it works, also introduced an interested operation OP_ACCEPT. In this post, I will introduce another interested operation OP_READ and how to gracefully read data from SocketChannel and handle closed socket channels\nServer Code # @Slf4j public class Server { public static void main(String[] args) throws IOException { ByteBuffer buffer = ByteBuffer.allocate(32); Selector selector = Selector.open(); log.debug(\u0026#34;Create a selector\u0026#34;); ServerSocketChannel ssc = ServerSocketChannel.open(); ssc.bind(new InetSocketAddress(9999)); ssc.configureBlocking(false); ssc.register(selector, SelectionKey.OP_ACCEPT, null); log.debug(\u0026#34;Register ServerSocketChannel with selector\u0026#34;); while (true) { Print.printDelimiter(); log.debug(\u0026#34;Listen to events from selection keys\u0026#34;); selector.select(); Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); log.debug(\u0026#34;Selected {} key(s)\u0026#34;, selectionKeys.size()); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = selectionKeys.iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if (key.isAcceptable()) { ServerSocketChannel channel = (ServerSocketChannel) key.channel(); SocketChannel sc = channel.accept(); sc.configureBlocking(false); log.debug(\u0026#34;Connected to client {}\u0026#34;, sc.getRemoteAddress()); SelectionKey scKey = sc.register(selector, 0, null); scKey.interestOps(SelectionKey.OP_READ); log.debug(\u0026#34;Register SocketChannel with selector\u0026#34;); } else if (key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); log.debug(\u0026#34;Read from client {}\u0026#34;, channel.getRemoteAddress()); channel.read(buffer); buffer.flip(); ByteBufferReader.readAll(buffer); buffer.clear(); } keyIterator.remove(); } } } } Compared with server code in post, the main change is inside the second while loop. Let\u0026rsquo;s analyze line by line to see the difference.\nConnect to clients\nif (key.isAcceptable()) { ServerSocketChannel channel = (ServerSocketChannel) key.channel(); SocketChannel sc = channel.accept(); ... } Here I first check if the key is an acceptable operation. If so, then I cast the channel from the selected key to ServerSocketChannel and let server accepts client\u0026rsquo;s connection Register read operation for ServerSocket\nif (key.isAcceptable()) { ... sc.configureBlocking(false); SelectionKey scKey = sc.register(selector, 0, null); scKey.interestOps(SelectionKey.OP_READ); } After creating a new SocketChannel, I register read operation for the channel with the selector by invoking SelectionKey.interestOps(int ops) method A new SelectionKey is added into keys Client sends messages\nelse if (key.isReadable()) { SocketChannel channel = (SocketChannel) key.channel(); log.debug(\u0026#34;Read from client {}\u0026#34;, channel.getRemoteAddress()); channel.read(buffer); buffer.flip(); ByteBufferReader.readAll(buffer); buffer.clear(); } Assume a client sends messages to the server. In that case, the SocketChannel key is selected and added to selectedKeys The data is read from the channel to the ByteBuffer and messages are printed in the terminal Demo # Start the server 23:25:01.524 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Create a selector 23:25:01.531 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Register ServerSocketChannel with selector ---------------------------------------------------- 23:25:01.531 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys A client connects 23:25:25.658 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 1 key(s) 23:25:25.660 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Connected to client /127.0.0.1:47346 23:25:25.660 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Register SocketChannel with selector ---------------------------------------------------- 23:25:25.660 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys The client sends messages 23:26:32.911 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 1 key(s) 23:26:32.911 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Read from client /127.0.0.1:47346 23:26:32.911 [main] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello Server! ---------------------------------------------------- 23:26:32.912 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys Open Questions: Why need to remove selected keys? # keyIterator.remove(); select method only adds items to SelectedKeys, but it doesn\u0026rsquo;t remove items. Hence, each time after handling event, we need to remove it. That\u0026rsquo;s why I use Iterator instead of for loop here. The better explain the problem if items are not removed, let\u0026rsquo;s comment the remove code and run above demo again.\nStart the server\n20:44:26.948 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Create a selector 20:44:26.955 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Register ServerSocketChannel with selector ---------------------------------------------------- 20:44:26.956 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys When starting the server, there is one key created, but no keys is added to SelectedKeys Client connects\n21:16:52.573 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 1 key(s) 21:16:52.582 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Connected to client /127.0.0.1:47438 21:16:52.582 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Register SocketChannel with selector ---------------------------------------------------- 21:16:52.582 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys A client connects to the server, the ssc key is added to SelectedKeys. select method is not blocked. A new ServerSocket is created and a new SelectionKeys is registered with the selector Cause this time we didn\u0026rsquo;t remove the ssc key, so it is still in the SelectedKeys Client sends messages\n21:23:20.865 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 2 key(s) Exception in thread \u0026#34;main\u0026#34; java.lang.NullPointerException at com.whatsbehind.netty_.nio.selector_.Server.main(Server.java:39) The client sends a message to the server, the sc (server socket) key is added to SelectedKeys, and two keys are selected When handle Accept event in the ssc key, this time there is no connection from clients, and cause the ServerSocketChannel is set as non-blocking mode, in line #39, what channel.accept() returns is null. Hence line #39 throws NullPointerException #37 ServerSocketChannel channel = (ServerSocketChannel) key.channel(); #38 SocketChannel sc = channel.accept(); #39 sc.configureBlocking(false); Clients disconnect # When clients disconnect, no matter it is normal SocketChannel close or exit with code -1, the connected SocketChannelin the server will receive a read event, but length of the message body is 0. Hence, current implementation channel.read(buffer); can\u0026rsquo;t handle client disconnection properly, and selector will keep selecting key of that channel and it causes infinite loop.\nMethod channel.read(buffer) returns an int value which is length of the byte read from the channel. When the read event is client disconnection, the method returns -1, so we can modify our code like below\nSocketChannel channel = (SocketChannel) key.channel(); int len = channel.read(buffer); if (len == -1) { key.cancel(); } else { buffer.flip(); ByteBufferReader.readAll(buffer); buffer.clear(); } We explicitly check the returned int from channel.read(buffer). If the value is -1, then we invoke key.cancel() method to deregister the SocketChannel from the selector After cancel, the selector stops listening to event from that channel, in other words, the key is removed from the keys Let\u0026rsquo;s take a look at the execution results:\n09:57:38.118 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Create a selector 09:57:38.128 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Register ServerSocketChannel with selector ---------------------------------------------------- 09:57:38.129 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys 09:57:40.136 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 1 key(s) 09:57:40.137 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Connected to client /127.0.0.1:47628 09:57:40.137 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Register SocketChannel with selector ---------------------------------------------------- 09:57:40.137 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys 09:57:42.913 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Selected 1 key(s) 09:57:42.913 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Read from client /127.0.0.1:47628 09:57:42.913 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Client /127.0.0.1:47628 is closed ---------------------------------------------------- 09:57:42.914 [main] DEBUG com.whatsbehind.netty_.nio.selector_.Server - Listen to events from selection keys "},{"id":22,"href":"/docs/programming/backend/java/thread/thread-safety/","title":"Thread Safety","section":"Thread","content":" Example and Best Practice # Shared Mutable State # Unsafe Use public class Counter { private int count = 0; public void increment() { count++; } public int getCount() { return count; } } Better Practice public class Counter { private int count = 0; public synchronized void increment() { count++; } public synchronized int getCount() { return count; } } - Adding `synchronized` on the methods ensure each method "},{"id":23,"href":"/docs/programming/backend/java/nio/io-model-summary/","title":"I/O  Model Summary","section":"Nio","content":" I/O Model # We have discussed some I/O models, like blocking I/O model and non-blocking I/O model. These two I/O models have their own problems which are low efficient.\nThen I introduce another I/O model Multiplexing which utilizes Selector to monitor registered keys and handle operations in a batch. This model provides high efficiency and handles multiple operations like accept (client connection) and read concurrently.\nIn this post, I will introduce two more I/O models, synchronous and asynchronous.\nSynchronous I/O Model # Definition # In the synchronous I/O model, the thread initiates the input or output operations and then it is blocked until the operation is completed. The thread remains inactive and can not perform any other tasks during this time. The thread resumes its executions after the operation has finished\nKey factors # Only one thread is involved to initiate the operation and get the result The thread is idle or blocked when waiting for the operation completing Linear execution flow Example # Code\npublic static void main(String[] args) throws IOException { FileChannel fc = FileChannel.open(Paths.get(\u0026#34;/path/to/file/data.txt\u0026#34;), StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(16); fc.read(buffer); buffer.flip(); ByteBufferReader.readAll(buffer); } Execution result\n16:18:51.605 [main] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello World! The example of synchronous I/O model is quite straight forward and easy. Only one thread is involved and the thread is blocked at blocking method fc.read(buffer) until data is loaded from the disk and copied to memories\nAsynchronous I/O Model # Definition # In asynchronous I/O model, when a thread initiates an I/O operation, it is not blocked and wait until the operation completes. Instead, the thread continues to execute, and another thread works on the I/O operation. Once the operation is complete, the initiating thread will be notified through mechanism like callbacks\nKey factors # Multiple threads are involved.\nOne thread is called main thread, which initiates the I/O operation, and it is not blocked during the operation. Instead, it continues to execute other tasks. Another thread is called working thread, its main task is to complete the I/O operation and calls back the main thread when the operation is complete. Main thread is not blocked\nConcurrency: Main thread can handle multiple I/O operations concurrently\nExample # Code\npublic static void main(String[] args) throws IOException, InterruptedException { AsynchronousFileChannel afc = AsynchronousFileChannel.open(Paths.get(\u0026#34;/path/to/file/data.txt\u0026#34;), StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(16); log.debug(\u0026#34;Start reading...\u0026#34;); afc.read(buffer, 0, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { @Override public void completed(Integer integer, ByteBuffer buffer) { buffer.flip(); ByteBufferReader.readAll(buffer); } @Override public void failed(Throwable throwable, ByteBuffer buffer) { throwable.printStackTrace(); } }); log.debug(\u0026#34;Finish reading...\u0026#34;); Thread.sleep(1000); } In afc.read(...) method of the async file channel, I pass in a callback object which has two methods completed and failed which are invoked by the working thread when the read operation completes or throws. I insert three logs before and after the read method and inside the completed method In the end of the code snippet, I force the main thread to sleep 1s. Because the working thread is a daemon thread, it terminates when main thread finishes all tasks. Sleeping 1s allows the work thread to complete Execution result\n16:34:14.824 [main] DEBUG com.whatsbehind.netty_.nio.asynchronous_.CallBackFileReader - Start reading... 16:34:14.826 [main] DEBUG com.whatsbehind.netty_.nio.asynchronous_.CallBackFileReader - Finish reading... 16:34:14.828 [Thread-0] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello World! Two threads are involved, main thread (main) and working thread (Thread-0) Logs Start reading... and Finish reading... are printed first and the thread is main thread. That means after initiating the read operation afc.read(...), the read operation is allocated to the working thread and the main thread is not blocked but continues to execute other tasks The data read from the disk later is printed and its executing thread is the working thread. That means the two threads are running concurrently Is Future asynchronous? # Code\npublic static void main(String[] args) throws IOException, InterruptedException, ExecutionException { AsynchronousFileChannel afc = AsynchronousFileChannel.open(Paths.get(\u0026#34;/path/to/file/data.txt\u0026#34;), StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(16); log.debug(\u0026#34;Start reading...\u0026#34;); Future\u0026lt;Integer\u0026gt; future = afc.read(buffer, 0); // Blocking method: main thread is blocked here until read operation completes future.get(); buffer.flip(); ByteBufferReader.readAll(buffer); log.debug(\u0026#34;Finish reading...\u0026#34;); Thread.sleep(1000); } Instead of utilizing callbacks to notify the main thread. We can use Future object to get the data after the read operation After calling afc.read(...), I invoke a blocking method future.get() to let the main thread wait here until the read operation completes. During this time, the working thread is working on the read operation and the main thread is blocked Execution result\n16:46:47.948 [main] DEBUG com.whatsbehind.netty_.nio.asynchronous_.FutureFileReader - Start reading... 16:46:47.952 [main] DEBUG com.whatsbehind.netty_.utility.ByteBufferReader - Hello World! 16:46:47.952 [main] DEBUG com.whatsbehind.netty_.nio.asynchronous_.FutureFileReader - Finish reading... The above code works as synchronous I/O model. Codes are executed like a linear way and all logs are printed in the main thread Is it asynchronous?\nIn my opinion, NO! This way has two threads involved, but comparing with synchronous I/O model, main thread only transfers its read job to the working thread. Main thread is still blocked at method future.get(), and it can\u0026rsquo;t execute other tasks. Further more, comparing with synchronous I/O model, this way has one more thread involved but doesn\u0026rsquo;t allow main to execute multiple tasks concurrently.\n"},{"id":24,"href":"/docs/programming/backend/java/nio/multiple-threads/","title":"Multiple Threads","section":"Nio","content":"In our previous posts of using Selector for connection and communication (read/write) between server and clients, we only utilize only one thread. Multiplexing is highly efficient, but some time-consumed tasks would affect the overall performance.\nIn this post, I will mimic some functions from Netty which allocates tasks to different threads to improve the performance\nComponent # We will focus on the components in the server side\nBoss # Boss runs under one thread Boss maintains one selector which only listens to ACCEPT events, in other words, boss is only responsible to accept client connections Worker # Worker runs in a separate thread Each worker has one selector which listens to READ and WRITE events After client\u0026rsquo;s connection, the newly created SocketChannel will be registered with one worker Architecture # Connect\nA client connects to the server Boss accepts the connection and creates a SocketChannel Register\nBoss registers the SocketChannel with one worker Worker starts to listen to READ and WRITE events from the newly registered channel Boss is decoupled with the channel Binding After registration, the SocketChannel is bound to the worker, and decoupled from the boss I/O operations including READ and WRITE are monitored and handled by the worker Implementation # Worker # @Getter @Setter @Slf4j public class Worker implements Runnable { private Thread thread; private Selector selector; private String name; private boolean start; public Worker(String name) { this.name = name; } public void register(SocketChannel sc) throws IOException { if (!start) { start = true; selector = Selector.open(); thread = new Thread(this, this.name); thread.start(); log.debug(\u0026#34;Start selector and thread in {}\u0026#34;, name); } sc.configureBlocking(false); sc.register(selector, SelectionKey.OP_READ, null); log.debug(\u0026#34;Register client [{}] with {}\u0026#34;, sc.getRemoteAddress(), name); } @Override public void run() { while (true) { try { log.debug(\u0026#34;{} is listening...\u0026#34;, name); selector.select(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); if (key.isReadable()) { SocketChannel sc = (SocketChannel) key.channel(); log.debug(\u0026#34;Reading message from client [{}]\u0026#34;, sc.getRemoteAddress()); ByteBuffer buffer = ByteBuffer.allocate(16); sc.read(buffer); buffer.flip(); ByteBufferReader.readAll(\u0026#34;Message: \u0026#34;, buffer); } } } catch (IOException e) { throw new RuntimeException(e); } } } } Field Selector: Monitors and handles read/write operations from registered channels Thread: Task executor Method run(): Worker implements Runnable. This method only does one thing: selector.select(): Listens to channel\u0026rsquo;s events Handle events register(): First time call: Create the Selector Create and start the thread Register the channel with the Selector Problems: # Let\u0026rsquo;s look at the two main operations of worker:\nmonitor (selector.select()); registration (sc.register(selector, SelectionKey.OP_READ, null);) Monitor is executed by the worker thread, cause method register() is invoked by other thread, so registration is executed by other thread (boss).\nWhile worker thread is blocked at line selector.select(), even though boss registers a new channel, the worker can\u0026rsquo;t start to monitor events from the new channel immediately until next round of monitor\nFix:\n@Getter @Setter @Slf4j public class Worker implements Runnable { private Thread thread; private Selector selector; private String name; private boolean start; + private ConcurrentLinkedQueue\u0026lt;Runnable\u0026gt; tasks = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); public Worker(String name) { this.name = name; } public void register(SocketChannel sc) throws IOException { if (!start) { start = true; selector = Selector.open(); thread = new Thread(this, this.name); thread.start(); log.debug(\u0026#34;Start selector and thread in {}\u0026#34;, name); } sc.configureBlocking(false); - sc.register(selector, SelectionKey.OP_READ, null); - log.debug(\u0026#34;Register client [{}] with {}\u0026#34;, sc.getRemoteAddress(), name); + tasks.add(() -\u0026gt; { + try { + sc.register(selector, SelectionKey.OP_READ, null); + } catch (IOException e) { + throw new RuntimeException(e); + } + }); + selector.wakeup(); } @Override public void run() { while (true) { try { log.debug(\u0026#34;{} is listening...\u0026#34;, name); selector.select(); + if (!tasks.isEmpty()) { + tasks.poll().run(); + log.debug(\u0026#34;Register client with {}\u0026#34;, name); + } Iterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator(); while (iterator.hasNext()) { SelectionKey key = iterator.next(); iterator.remove(); if (key.isReadable()) { SocketChannel sc = (SocketChannel) key.channel(); log.debug(\u0026#34;Reading message from client [{}]\u0026#34;, sc.getRemoteAddress()); ByteBuffer buffer = ByteBuffer.allocate(16); ByteBuffer buffer = ByteBuffer.allocate(32); sc.read(buffer); buffer.flip(); ByteBufferReader.readAll(\u0026#34;Message: \u0026#34;, buffer); } } } catch (IOException e) { throw new RuntimeException(e); } } } } I create a Queue as the bridge between two threads\nInstead let other thread execute the registration, I add a Runnable task in the queue, and let the worker thread execute the registration\nTo fix the bug that the selector can\u0026rsquo;t immediately monitor newly registered channels while it is monitoring (blocked at selector.select()), I invoke method selector.wakeup() which unblocks the selector and let it continue to execute codes after adding the task to the queue,\nBefore handling events from selected keys, worker will first check if there are any registration tasks in the queue and do the registration if yes\n"},{"id":25,"href":"/docs/programming/backend/java/net/tcp-socket/","title":"Tcp Socket","section":"Net","content":" What Is a Socket? # Server socket listens to a port Normally, a server runs on a specific computer and has a socket that is bound to a specific port number. The server just waits, listening to the socket for a client to make a connection request.\nCient connects to the server with server ip and port On the client-side: The client knows the hostname of the machine on which the server is running and the port number on which the server is listening. To make a connection request, the client tries to rendezvous with the server on the server\u0026rsquo;s machine and port. The client also needs to identify itself to the server so it binds to a local port number that it will use during this connection. This is usually assigned by the system.\nServer accepts connection and creates a new socket If everything goes well, the server accepts the connection. Upon acceptance, the server gets a new socket bound to the same local port and also has its remote endpoint set to the address and port of the client. It needs a new socket so that it can continue to listen to the original socket for connection requests while tending to the needs of the connected client.\nSocket is successfully created on client On the client side, if the connection is accepted, a socket is successfully created and the client can use the socket to communicate with the server.\nThe client and server can now communicate by writing to or reading from their sockets. [1]\nExamples # Create Sockets # Server\npublic class Server_ { public static void main(String[] args) throws IOException { // A server socket listens to port 8888 ServerSocket serverSocket = new ServerSocket(8888); // The program is blocked here waiting for client connecting Socket socket = serverSocket.accept(); // Your business logic ... // Close both sockets to release system resource socket.close(); serverSocket.close(); } } First we create a ServerSocket listening to port 8888 Before accepting any connections, the program is blocked at line Socket socket = serverSocket.accept(); A client requests to connect to the server. After the server accepts the request, a new socket will be created in the server After your business logic, close the socket and server socket to release system resources Client\npublic class Client_ { public static void main(String[] args) throws IOException { // Create a new socket and connect to port 8888 on the server Socket socket = new Socket(InetAddress.getByName(\u0026#34;\u0026lt;host-name\u0026gt;\u0026#34;);, 8888); // Your business logic ... // Close the socket to release system resource socket.close(); } } First we create a socket connecting to port 8888 of the host Once the connection is successfully created, a socket will be created After your business logic, close the socket to release system resources Upload File from Client to Server # Client\npublic class Client_ { public static void main(String[] args) throws IOException { // Create a new socket and connect to a specific port of the server Socket socket = new Socket(InetAddress.getLocalHost(), 8888); // Read file from disk String filePath = \u0026#34;/path/to/the/file\u0026#34;; FileInputStream bis = new FileInputStream(filePath); byte[] data = inputStreamToByteArray(bis); bis.close(); System.out.println(\u0026#34;Client reads a file from disk\u0026#34;); // Send byte data of the file to the server OutputStream os = socket.getOutputStream(); os.write(data); // You need to shut down the output stream, otherwise the server will hang up // It\u0026#39;s a signal let server know that you\u0026#39;re done sending data // TODO: What\u0026#39;s the corresponding TCP packet for this? socket.shutdownOutput(); System.out.println(\u0026#34;Client uploads a file to server\u0026#34;); // Close streams and socket os.close(); socket.close(); } } Client reads a file in the disk to a FileInputStream, and invoke an utility method inputStreamToByteArray to convert InputStream to a byte array Then client writes the byte data into its output stream and sends it to the server Close all streams and socket to release system resources Utility method:\npublic class InputStreamUtil { public static byte[] inputStreamToByteArray(InputStream is) throws IOException { byte[] buf = new byte[1024]; ByteArrayOutputStream bos = new ByteArrayOutputStream(); int len; while((len = is.read(buf)) != -1) { bos.write(buf, 0, len); } byte[] result = bos.toByteArray(); bos.close(); return result; } } The utility method creates a ByteArrayOutputStream as a buffer to store data read from the input stream Contantly reads data from the input stream and writes the data into the ByteArrayOutputStream Invokes toByteArray method to get a byte array holding the data Server\npublic class Server_ { public static void main(String[] args) throws IOException { // A server socket waits for requests to come in over the network. ServerSocket serverSocket = new ServerSocket(8888); // Listens to a connection and accepts it. Returns a new socket Socket socket = serverSocket.accept(); // Read data from input stream InputStream is = socket.getInputStream(); byte[] data = inputStreamToByteArray(is); System.out.println(\u0026#34;Server received file uploaded from client\u0026#34;); // Save the file to local disk String filePath = \u0026#34;/path/to/save/the/file\u0026#34;; BufferedOutputStream bos = new BufferedOutputStream(new FileOutputStream(filePath)); bos.write(data); bos.close(); // Close streams and socket is.close(); socket.close(); serverSocket.close(); } } Server socket listens to port 8888 in local host Creates a new socket to accept connection from the client Reads data from socket\u0026rsquo;s input stream Writes byte data to disk through FileOutputStream Close all streams and sockets to release system resources "},{"id":26,"href":"/docs/programming/backend/java/io/decorator-pattern-in-java-io/","title":"Decorator Pattern in Java IO","section":"Io","content":" Node Streams (Low-Level Streams) # Definition:\nNode Streams connect directly with the source of the data They read data from or write data to a specific location (like a file, memory, or network socket). Example: FileInputStream is a node stream that reads byte data from a file.\nFile file = new File(\u0026#34;example.txt\u0026#34;); FileInputStream fis = new FileInputStream(file); Here, FileInputStream is directly reading the bytes from the file \u0026ldquo;example.txt\u0026rdquo;. It\u0026rsquo;s a direct connection between the Java program and the file.\nProcessing Streams (High-Level Streams) # Definition:\nProcessing Streams are built on top of node streams to provide additional functionality, like buffering, filtering, reading objects, etc. They don\u0026rsquo;t write or read data directly to or from data source, but delegate this job to node streams. Example: BufferedInputStream is a processing stream that adds buffering capabilities to another input stream, such as FileInputStream.\nFileInputStream fis = new FileInputStream(\u0026#34;example.txt\u0026#34;); BufferedInputStream bis = new BufferedInputStream(fis); BufferedInputStream does not connect directly to the file. Instead, it wraps the FileInputStream and adds buffering to it. When you read from a BufferedInputStream, it retrieves data from the buffer, and when the buffer is empty, it reads another large chunk of data from the FileInputStream and fills the buffer. This minimizes the number of interactions with the file system, which is much slower than reading from a buffer in memory.\nCombining Node and Processing Streams # Typically, you chain processing streams together to get both their benefits. For instance, wrapping a FileInputStream with a BufferedInputStream.\nFile file = new File(\u0026#34;example.txt\u0026#34;); InputStream is = new BufferedInputStream(new FileInputStream(file)); ... is.close(); In this example, we use FileInputStream to connect to the file and BufferedInputStream to add buffering. The data still comes from the file, but it passes through the buffer, which can be read from more quickly than the file.\nDecorator Pattern in Java IO Stream # Component (Node Stream) # Definition: The component is the primary or underlying object that has the original behavior, which is to read data from data source for node streams. In Java IO: FileInputStream and FileReader are example of components. They provide the basic functionality for byte and character stream handling. Decorator (Processing Stream) # Definition: Decorators implement or extend the same interface as the component they are going to decorate. They compose the instance of component and provide an enhanced interface with added responsibilities.- In Java IO: BufferedInputStream, BufferedOutputStream, BufferedReader, and BufferedWriter are examples of decorators. They add buffering to the streams they decorate. Key Features of Decorator # Delegation: The decorator delegates the work to the component it decorates and then adds its own behavior before or after delegating. This is a key feature because it means the decorator itself doesn\u0026rsquo;t handle the primary operations; it relies on the component to do so.\npublic class BufferedInputStream extends InputStream { private InputStream inner; public BufferedInputStream(InputStream inner) { this.inner = inner; } public int read() throws IOException { ... // own behavior of decorator return inner.read(); } } Add Features Over Component Dynamically: Because decorators implement or extend the same interface as the component they are going to decorate, that means they can be decorated by other decorators. Decorators can be nested and combined in any order to add multiple behaviors.\nInputStream input = new FileInputStream(\u0026#34;file.txt\u0026#34;); InputStream buffered = new BufferedInputStream(input); InputStream dataInput = new DataInputStream(buffered); Q \u0026amp; A of Decorator Pattern # What\u0026rsquo;s the main difference between component and decorator?Component and decorator both implement or extend same interface or superclass. However, components don\u0026rsquo;t compose an instance of the interface or superclass, so it can only perform the original behavior. Decorators compose an instance of the interface or superclass, which can be delegated to perform the original behavior. What\u0026rsquo;s the difference between strategy and decorator pattern?Key feature for decorator and strategy pattern is delegation. However, decorators extend or implements same interface or superclass it decorates, which mean decorators themselves can be decorated also, which add extra features dynamically during runtime. "},{"id":27,"href":"/docs/programming/backend/java/io/object-input-and-output-stream/","title":"ObjectInputStream and ObjectOutputStream","section":"Io","content":"This post will introduce two new processing streams, ObjectInputStream and ObjectOutputStream, which are used to deserialize and serialize objects and primitive data.\nObjectInputStream # Purpose: To deserialize objects and primitive data written using ObjectOutputStream. It allows you to read bytes from a source (like a file or network socket) and reconstructs objects from those bytes.\nKey Features: Processing stream: reads serialized objects from an underlying InputStream.\nCommon Use Case: Commonly used in networking (for sending objects across a network) or for persisting objects to files.\nExample of ObjectInputStream # Deserialize objects from a file\nFileInputStream fis = new FileInputStream(\u0026#34;example.ser\u0026#34;); ObjectInputStream ois = new ObjectInputStream(fis); MyClass o = (MyClass) ois.readObject(); ois.close(); Deserialize objects from network\nSocket socket = new Socket(\u0026#34;example.com\u0026#34;, 8080); InputStream is = socket.getInputStream(); ObjectInputStream ois = new ObjectInputStream(is); MyClass o = (MyClass) ois.readObject(); ois.close(); ObjectOutputStream # Purpose: To serialize objects and primitive data types to an OutputStream. It converts objects into a byte stream that can then be written to a file, sent over a network, etc.\nKey Features: Processing stream: serializes objects and primitives to an underlying OutputStream.\nCommon Use Case: Used for saving object states, caching objects, or sending objects over a network.\nExample of ObjectInputStream # Serialize objects to a file\nFileOutputStream fos = new FileOutputStream(\u0026#34;example.ser\u0026#34;); ObjectOutputStream oos = new ObjectOutputStream(fos); MyClass o = MyClass(); oos.writeObject(o); oos.close(); Serialize objects to network\nSocket socket = new Socket(\u0026#34;example.com\u0026#34;, 8080); OutputStream os = socket.getOutputStream(); ObjectOutputStream oos = new ObjectOutputStream(os); MyClass o = MyClass(); oos.writeObject(o); oos.close(); Serializable Interface # public interface Serializable {} Purpose: The Serializable interface is a marker interface (it has no methods) that indicates the implementor can be serialized by ObjectOutputStream. "},{"id":28,"href":"/docs/programming/backend/java/io/stream-reader-bridge-of-byte-and-char/","title":"Stream Reader: Bridge of Byte and Char","section":"Io","content":"There are two special readers in Java IO package, they are InputStreamReader and OutputStreamWriter which serve as bridge between byte data and character data\nInputStreamReader # Important constructor\npublic class InputStreamReader extends Reader { public InputStreamReader(InputStream in, Charset cs); } Key feature (Bridge from byte to char)\nCharacter Encoding: Data stored in files or transmitted over networks is often in the form of bytes. When such data represents text, it needs to be decoded using a specific character encoding (like UTF-8, ISO-8859-1, etc.) to be converted into characters that can be processed by the program. InputStreamReader facilitates this by decoding the byte stream into characters according to the specified or default charset.\nExample # // A socket connection to a server that sends text data Socket socket = new Socket(\u0026#34;example.com\u0026#34;, 80); InputStream input = socket.getInputStream(); // Use InputStreamReader to decode the byte stream from the socket // Assume the server sends data encoded in UTF-8 InputStreamReader reader = new InputStreamReader(input, StandardCharsets.UTF_8); int data; while ((data = reader.read()) != -1) { char character = (char) data; // Process the character } reader.close(); OutputStreamWriter # Bridge from Character to Byte: It bridges Writer (character-oriented abstraction) with OutputStream (byte-oriented stream). Customizable Encoding: Allows specifying a charset for encoding characters, making the character writing process customizable and flexible. "},{"id":29,"href":"/docs/programming/backend/java/io/io-stream/","title":"Java IO Stream","section":"Io","content":" What is stream? # Java Input/OutputStream and Reader/Writer are essential components of the Java I/O (Input/Output) library, designed to facilitate reading and writing data in various forms from different sources within Java applications. These classes serve as a bridge between your application and external data sources, making it easier to perform I/O operations efficiently and consistently. In this post, we will explore what Input/OutputStream and Reader/Writer are, their relationships, and how they classify based on the type of data and data source.\nBelow image illustrates the relationship among stream in Java IO, application and data source: Classification # Stream in Java IO could be classified by data type and data flow\n| Stream flow | Byte Stream | Character Stream | |-----------------------------|------------------|------------------| | input: data source -\u0026gt; app | InputStream | Reader | | output: app -\u0026gt; data source | OutputStream | Writer | Data type\nByte data: InputStream/OutputStream Character data: Reader/Writer Data flow\nInput (data source -\u0026gt; app): InputStream/Reader Output (app -\u0026gt; data source): OutputStream/Writer Class Hierarchy # java.io ‚îÇ ‚îú‚îÄ‚îÄ Byte Stream ‚îÇ ‚îú‚îÄ‚îÄ InputStream (abstract) ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ByteArrayInputStream ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ FileInputStream ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ FilterInputStream ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ BufferedInputStream ‚îÇ ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ DataInputStream ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ PushbackInputStream ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ ObjectInputStream ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ PipedInputStream ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ OutputStream (abstract) ‚îÇ ‚îú‚îÄ‚îÄ ByteArrayOutputStream ‚îÇ ‚îú‚îÄ‚îÄ FileOutputStream ‚îÇ ‚îú‚îÄ‚îÄ FilterOutputStream ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ BufferedOutputStream ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ DataOutputStream ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ PrintStream ‚îÇ ‚îú‚îÄ‚îÄ ObjectOutputStream ‚îÇ ‚îî‚îÄ‚îÄ PipedOutputStream ‚îÇ ‚îî‚îÄ‚îÄ Character Stream ‚îú‚îÄ‚îÄ Reader (abstract) ‚îÇ ‚îú‚îÄ‚îÄ BufferedReader ‚îÇ ‚îú‚îÄ‚îÄ CharArrayReader ‚îÇ ‚îú‚îÄ‚îÄ FileReader ‚îÇ ‚îú‚îÄ‚îÄ FilterReader ‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ BufferedReader ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ PushbackReader ‚îÇ ‚îú‚îÄ‚îÄ InputStreamReader ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ FileReader ‚îÇ ‚îú‚îÄ‚îÄ PipedReader ‚îÇ ‚îú‚îÄ‚îÄ StringReader ‚îÇ ‚îî‚îÄ‚îÄ FilterReader ‚îÇ ‚îî‚îÄ‚îÄ Writer (abstract) ‚îú‚îÄ‚îÄ BufferedWriter ‚îú‚îÄ‚îÄ CharArrayWriter ‚îú‚îÄ‚îÄ FileWriter ‚îú‚îÄ‚îÄ FilterWriter ‚îú‚îÄ‚îÄ OutputStreamWriter ‚îÇ ‚îî‚îÄ‚îÄ FileWriter ‚îú‚îÄ‚îÄ PipedWriter ‚îú‚îÄ‚îÄ PrintWriter ‚îî‚îÄ‚îÄ StringWriter There are more than 40 classes under Java IO, and with a lot of different types of Input/Output Stream and Writer/Reader. However, IO Stream has a well defined hierarchy, here are some of properties of the it:\nJava IO has four abstract stream classes, they are InputStream OutputStream Reader Writer Every abstract stream class has multiple subclasses, and every subclass uses the name of its superclass as its suffix, for example: FileInputStream is subclass of InputStream, its suffix is InputStream, which is superclass name All subclasses under one abstract stream superclass (e.g. InputStream) can be classifed as two types Node Streams: These are the fundamental streams that directly interact with the specific data sources or destinations. They are the building blocks for reading or writing data and connect directly to the source, such as a file, an array in memory, or a network socket. Example FileInputStream ByteArrayInputStream Processing Streams: Also known as wrapper streams or filter streams, these streams do not directly read or write data to the data source. Instead, they are used to wrap around other streams (node streams or other processing streams) to provide additional functionalities like buffering, data conversion, or performance enhancement. Example BufferedInputStream DataInputStream The concept of node stream and processing stream may be hard to understand now. We will dive deeper into them with code examples and introduce the decorator design pattern underlying processing stream.\nInputStream # FileStreamInput # FileStreamInput is a subclass of InputStream. It\u0026rsquo;s a node steam whose data source is files from disk\nExample\nFile file = new File(\u0026#34;example.txt\u0026#34;); InputStream is = new FileInputStream(file); int content; while ((content = is.read()) != -1) { // process the content } is.close(); Read binary files\nFileInputSteam can not only read text files. More importantly, cause it is a byte stream, it is normally used to read binary files, like images, videos and any non-text files. Actually, we should only use InputStream to read binary files. Here is the main problem with using Reader to reading binary files:\nReader classes are deisnged to read character data. When you use a Reader to read a binary file, it may attempt to interpret non-character bytes as character, leading to data curruption and loss of imformation\nBufferedInputStream # BufferedInputStream is a processing stream\n"},{"id":30,"href":"/docs/programming/backend/java/io/file/","title":"Java File","section":"Io","content":"The File class in Java, found in the java.io package, is not used for file content manipulation (reading/writing) but for file and directory pathnames operations. It\u0026rsquo;s used to obtain or manipulate the information associated with a file or directory, such as metadata, permissions, and path details.\nCommonly Used APIs in File Class for Files and Directories # File Handling # Create a New File\ncreateNewFile(): Creates a new file if it does not exist. File myFile = new File(\u0026#34;myfile.txt\u0026#34;); if (myFile.createNewFile()) { System.out.println(\u0026#34;File created.\u0026#34;); } else { System.out.println(\u0026#34;File already exists.\u0026#34;); } Delete a File\ndelete(): Deletes the file or directory. if (myFile.delete()) { System.out.println(\u0026#34;File deleted.\u0026#34;); } else { System.out.println(\u0026#34;Failed to delete the file.\u0026#34;); } Check if File Exists\nexists(): Checks if the file or directory exists. if (myFile.exists()) { System.out.println(\u0026#34;The file exists.\u0026#34;); } else { System.out.println(\u0026#34;The file does not exist.\u0026#34;); } Read File Attributes\ncanRead(), canWrite(), isHidden(): Check read/write permission or if the file is hidden. length(): Returns the file size in bytes. lastModified(): Returns the last modified timestamp. Directory Handling # Create a Directory\nmkdir(): Creates the directory named by this abstract pathname. File dir = new File(\u0026#34;mydir\u0026#34;); if (dir.mkdir()) { System.out.println(\u0026#34;Directory created.\u0026#34;); } else { System.out.println(\u0026#34;Failed to create directory.\u0026#34;); } List Files and Directories\nlist(): Returns an array of strings naming the files and directories in the directory. String[] files = dir.list(); for (String file : files) { System.out.println(file); } Check Directory Status\nisDirectory(): Checks if the File instance is a directory. isFile(): Checks if the File instance is a regular file. File Path Operations\ngetPath(), getAbsolutePath(), getCanonicalPath(): Various ways to get the file/directory path. "},{"id":31,"href":"/docs/programming/backend/java/reflection/","title":"Reflection","section":"Java","content":" Introduction to Java Reflection # Java Reflection is a powerful feature that allows runtime introspection of classes, objects, and their members. It enables Java programs to manipulate internal properties and methods of classes dynamically. Reflection is especially useful in scenarios where the program needs to interact with classes and objects whose properties are not known at compile time.\nClass Object # The heart of Java\u0026rsquo;s reflection mechanism. It\u0026rsquo;s an instance that represents classes and interfaces in a running Java application. Every class, including primitive types and arrays, has a corresponding Class object.\nAcquiring Class Objects # Class.forName(\u0026quot;ClassName\u0026quot;): Loads the class dynamically. ClassName.class: Directly accesses the class if it\u0026rsquo;s known at compile time. object.getClass(): Retrieves the runtime class of an object. ClassLoader: For more complex scenarios, especially in modular applications. For primitive types: int.class or Integer.TYPE. // Using Class.forName() Class cls1 = Class.forName(\u0026#34;com.example.model.Person\u0026#34;); // Using .class syntax Class cls2 = Person.class; // From an instance of the class Person person = new Person(); Class cls3 = person.getClass(); // Using ClassLoader ClassLoader classLoader = Person.class.getClassLoader(); Class cls4 = classLoader.loadClass(\u0026#34;com.example.model.Person\u0026#34;); // Primitive type class Class intCls = int.class; Uniqueness and Singleton Nature of Class Object in Java Reflection # Singleton Pattern in Class Objects # The singleton pattern ensures that a class has only one instance and provides a global point of access to that instance. In the context of Java\u0026rsquo;s Class objects, the JVM enforces this pattern.\nHow It Works # Unique Instance: When a class is loaded into the JVM, a single instance of Class is created to represent it. This instance contains all the metadata about the class, including its methods, fields, constructors, and superclass. Global Accessibility: This unique Class instance is globally accessible through different means like Class.forName(), ClassName.class, and object.getClass(). JVM Management: The JVM manages these Class objects, ensuring that for each class loaded, only one Class object exists. Benefits # Consistency: Since there\u0026rsquo;s only one Class object per class, it guarantees consistency across the application. All parts of the program refer to the same metadata of a class. Efficiency: Reduces memory overhead by avoiding multiple instances of metadata for the same class. Example # Class cls1 = String.class; Class cls2 = \u0026#34;Hello, World!\u0026#34;.getClass(); Class cls3 = Class.forName(\u0026#34;java.lang.String\u0026#34;); // All of these Class objects are the same boolean areSame = (cls1 == cls2) \u0026amp;\u0026amp; (cls2 == cls3); // true Loading of Variables in a Class # In Java, variables are loaded and initialized based on their type (static or instance) and the sequence of their declaration in the class.\nStatic Variables # Initialization: Static variables are initialized when the class is first loaded into the JVM. Order of Execution: Static blocks and static variables are executed in the order they appear in the class. public class MyClass { static String staticVar = \u0026#34;Static Variable\u0026#34;; static { System.out.println(staticVar); // Accessed in static block staticVar = \u0026#34;Modified in Static Block\u0026#34;; } } // When MyClass is loaded, the static block is executed after staticVar is initialized. Instance Variables # Initialization: Instance variables are initialized when an instance of the class is created. Constructor Execution: They are typically initialized before the constructor\u0026rsquo;s execution or within it. Field # Represents the fields of a class. You can use Field objects to get and set field values dynamically.\nField field = cls.getField(\u0026#34;fieldName\u0026#34;); field.setAccessible(true); // For private fields Object value = field.get(objectInstance); field.set(objectInstance, newValue); Method # Represents a method of a class. You can invoke methods dynamically using Method objects.\nMethod method = cls.getMethod(\u0026#34;methodName\u0026#34;, parameterTypes); method.setAccessible(true); // For private methods method.invoke(objectInstance, arguments); Constructor # Represents a constructor of a class. Constructors can be used to create new instances of a class dynamically.\nConstructor constructor = cls.getConstructor(parameterTypes); Object newInstance = constructor.newInstance(initargs); TODO # For static variable loading, show the example with static variables declared before and after static block Better example about Method, Field and Constructor, like method getDeclaredMethod or getDeclaredField, and how to get a specific constructor if the class has multiples ones Reference # Perfect Video in Chinese\n"},{"id":32,"href":"/docs/programming/os/linux/linux-manual/","title":"Linux Manual","section":"Linux","content":" Vim: Three Modes # Normal mode Insert mode Command mode Command Mode # Type : to enter.\nw (write): save. q: quit. x (==wq): save and quit. set nu: show line numbers. set nonu: do not show line numbers. Normal Mode # y (yank): copy. p: paste. 5yy: copy 4 lines. dd: delete. 4dd: delete 4 lines. /word_to_search + Enter: search a word. n: next. G: last line. gg (go to the top\u0026hellip;): first line. u: undo. Ctrl + r: redo. 20gg / 20G: go to line 20. User Login and Logout Commands # Command: su - \u0026lt;user\u0026gt;: switch user. logout: If you are the root user, you will be switched to the standard user. If you are not the root user, you will be logged out of the Linux system. adduser \u0026lt;user\u0026gt;: add a user under /home directory. -d \u0026lt;home_dir\u0026gt;: specify the home directory for the new user. passwd: set the password for the root user. \u0026lt;user\u0026gt;: set the password for the user. User # User home directory: /home/\u0026lt;user\u0026gt;. File and Directory Commands # ls: List files and directories in the current directory. Example: ls Common options: -h: make the file sizes in the output more human-readable cd: Change the current directory. Example: cd /path/to/directory pwd: Print the current working directory. Example: pwd mkdir: Create a new directory. Example: mkdir new_directory rmdir: Remove a directory (only if it\u0026rsquo;s empty). Example: rmdir empty_directory rm: Remove files or directories. Example: rm file.txt or rm -r directory cp: Copy files and directories. Example: cp file.txt /path/to/destination mv: Move or rename files and directories. Example: mv file.txt new_name.txt or mv file.txt /path/to/destination touch: Create an empty file. Example: touch new_file.txt cat: Display the content of a file. Options: -n: show line number Example: cat file.txt more and less: Display file content page by page. Example: more file.txt or less file.txt head and tail: Display the beginning or end of a file. Example: head file.txt or tail file.txt chmod: Change file permissions. Example: chmod 755 file.txt chown: Change file ownership. Example: chown user:group file.txt ln: Create symbolic links or hard links to files or directories. Example: ln -s target link_name (for symbolic links) or ln target link_name (for hard links) history: Display latest executed commands in current shell session Use case: history !100: re-execute executed command in line 100 \u0026gt; \u0026amp; \u0026gt;\u0026gt;: In Linux and Unix-like operating systems, \u0026gt; and \u0026raquo; are used as operators for redirecting output from commands. They are often used in the command line to control where the output of a command is sent Difference: \u0026gt; overwrite existed content, but \u0026gt;\u0026gt; append command output to to the output of a file Example: echo \u0026quot;Hello, World!\u0026quot; \u0026gt; output.txt echo \u0026quot;Appended text\u0026quot; \u0026gt;\u0026gt; output.txt echo file1.txt \u0026gt;\u0026gt; file2.txt ls -l \u0026gt;\u0026gt; output.txt Date Command # Date Search \u0026amp; Find Commands # find: Search for files and directories. Basic syntax: find [path] [options] [expression] Common options: -name \u0026lt;pattern\u0026gt;: Search for files and directories with a specific name or pattern. -type \u0026lt;type\u0026gt;: Specify the type of file (e.g., f for regular files, d for directories). -mtime \u0026lt;days\u0026gt;: Search for files modified within a certain number of days. -size \u0026lt;size\u0026gt;: Search for files of a specific size (e.g., +10M for files larger than 10 megabytes). -user \u0026lt;username\u0026gt;: Search for files owned by a specific user. -group \u0026lt;groupname\u0026gt;: Search for files in a specific group. -exec \u0026lt;command\u0026gt; {} \\;: Execute a command on each matching file or directory. -print: Display the path of each matching file or directory. Example: find . -name \u0026quot;example.txt\u0026quot; find ~ -type d -user john find /path/to/directory -type f -mtime +7 -exec rm {} ; find . -type f -size +100M find /path/to/directory -type f -name \u0026quot;*.log\u0026quot; locate: Quick find location of a file. It uses pre-built database (updatedb command to create index for dirs and files) to provide fast search results Usage: sudo yum install mlocate: install locate in CentOS updatedb: create a db to store index of all files in your linux system locate example.txt: find example.txt files Reminder Keep in mind that locate is a powerful tool for quickly finding files and directories on your system. However, it doesn\u0026rsquo;t search for files in real-time, so you need to ensure that the database is updated regularly using the updatedb command for accurate results. grep: filter and find "},{"id":33,"href":"/docs/programming/web/glossary/cors/","title":"CORS","section":"Glossary","content":" What\u0026rsquo;s CORS # CORS is a mechanism to stop you from accessing resource in one origin from another origin. For example, there is an image img.jpg from origin images.com, if you don\u0026rsquo;t have CORS set properly, you can\u0026rsquo;t access the img.jpg from other origins like yourOrigin.com.\nWhy needs CORS # CORS is mainly for security usage. Image that your browser stores credential cookies of domain bank.com which is the website of you bank account, and a hacking website hacking.com want to access your bank information and make a transaction from your bank. If without CORS, the javascript script from hacking.com is able to get the cookies under domain bank.com and make requests to bank.com. CORS can protect your website from malicious requests\nAccess-Control-Allow-Origin Header # Issue Demonstration # Start a local host\nconst express = require(\u0026#34;express\u0026#34;); const app = express(); app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.json({ name: \u0026#34;Hello\u0026#34;, value: \u0026#34;World\u0026#34;}) }); app.listen(3000); In your browser, navigate to http://localhost:3000. Open console and make a GET request to http://localhost:3000\nfetch(\u0026#34;http://localhost:3000\u0026#34;).then((req) =\u0026gt; req.json()).then(console.log); You will receive a successful response\n{name: \u0026#39;Hello\u0026#39;, value: \u0026#39;World\u0026#39;} You didn\u0026rsquo;t see any CORS issues, cause you were making request from http://localhost:3000 to same origin.\nOpen a new tab in your browser, navigate to www.google.com, and make a same request. You will see error like:\nAccess to fetch at \u0026#39;http://localhost:3000/\u0026#39; from origin \u0026#39;https://www.google.com\u0026#39; has been blocked by CORS policy: No \u0026#39;Access-Control-Allow-Origin\u0026#39; header is present on the requested resource. If an opaque response serves your needs, set the request\u0026#39;s mode to \u0026#39;no-cors\u0026#39; to fetch the resource with CORS disabled. Solution # Add www.google.com in allowed origins in your CORS config\nconst express = require(\u0026#34;express\u0026#34;); const app = express(); const cors = require(\u0026#34;cors\u0026#34;); app.use(cors({ origin: \u0026#34;https://www.google.com\u0026#34; })); app.get(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.json({ name: \u0026#34;Hello\u0026#34;, value: \u0026#34;World\u0026#34;}) }); app.listen(3000); Make a same request again to local host, and the error is gone and you will see response printed in console:\n{name: \u0026#39;Hello\u0026#39;, value: \u0026#39;World\u0026#39;} Access-Control-Allow-Methods Header # Problem Demonstration # To demonstration the problem with Access-Control-Allow-Methods header\nI add GET and POST as allowed methods in CORS config, which limits that clients can only use GET or POST methods in their requests to the server Also, I changed the method provided by the server from GET to PUT app.use(cors({ origin: \u0026#34;https://www.google.com\u0026#34;, methods: [\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;], })); app.put(\u0026#39;/\u0026#39;, (req, res) =\u0026gt; { res.json({ name: \u0026#34;Hello\u0026#34;, value: \u0026#34;World\u0026#34;}) }); Then let\u0026rsquo;s make request in the console under www.google.com domain\nfetch(\u0026#34;http://localhost:3000\u0026#34;, {method: \u0026#34;PUT\u0026#34;}).then((req) =\u0026gt; req.json()).then(console.log); We will see error:\nwww.google.com/:1 Access to fetch at \u0026#39;http://localhost:3000/\u0026#39; from origin \u0026#39;https://www.google.com\u0026#39; has been blocked by CORS policy: Method PUT is not allowed by Access-Control-Allow-Methods in preflight response. Solution # Add PUT in allowed methods\napp.use(cors({ origin: \u0026#34;https://www.google.com\u0026#34;, methods: [\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;], })); Make the same request from www.google.com again, and this time the error was gone and we receive correct response.\n{name: \u0026#39;Hello\u0026#39;, value: \u0026#39;World\u0026#39;} Checking console, we can see two requests, the first request, which is called preflight request, and its response header is lik below:\nHTTP/1.1 204 No Content Access-Control-Allow-Origin: https://www.google.com Vary: Origin, Access-Control-Request-Headers Access-Control-Allow-Methods: GET,POST,PUT Content-Length: 0 Connection: keep-alive Keep-Alive: timeout=5 The headers tell the browser that cross-origin request to \u0026lsquo;http://localhost:3000/\u0026rsquo; is allowed for origin https://www.google.com, but only applies to three methods: GET, POST and PUT, which are same as what we defined in our CORS config.\nAnother request is the real cross-origin request, with PUT method, and server returns response with content.\nPreflight Request # We demonstrate Access-Control-Allow-Methods problem, but what is preflight response in above error\nPreflight request is an OPTIONS request automatically sent by browser before a cross origin request. Preflight request is used to determine if a cross origin request is safe. Preflight request including header Origin, Access-Control-Request-Method and Access-Control-Request-Headers (Optional) How Does Preflight Request Work # Browser sends an OPTIONS request to the server with headers mentioned above OPTIONS / HTTP/1.1 Access-Control-Request-Method: PUT Host: localhost:3000 Origin: https://www.google.com Sec-Fetch-Mode: cors Sec-Fetch-Site: cross-site Server receives the preflight request and check its CORS configuration. It determines if the real cross-origin request has proper permission by checking origin, method and headers in the preflight request\nIf the real request is allowed, server responds to the preflight request with appropriate CORS headers, including allowed origins, methods and headers.\nAfter receiving preflight response from the server, if the server allows the request, then browser will send the real cross-origin request to the server. If not, browser will block the request and prevent it from reaching the server\nIf we include headers in the request\nfetch(\u0026#34;http://localhost:3000\u0026#34;, { method: \u0026#34;PUT\u0026#34;, headers: { \u0026#34;Customer-Header\u0026#34;: \u0026#34;key=value\u0026#34;, \u0026#34;X-Customer-Header\u0026#34;: \u0026#34;key=value\u0026#34;, \u0026#34;Cookie\u0026#34;: \u0026#34;value\u0026#34; } }).then((req) =\u0026gt; req.json()).then(console.log); Here we include two customer headers: Customer-Header and X-Customer-Header, and the preflight request and response are like below\nRequest OPTIONS / HTTP/1.1 Access-Control-Request-Headers: customer-header,x-customer-header Access-Control-Request-Method: PUT Host: localhost:3000 Origin: https://www.google.com Some headers are omitted, but you can see here preflight request tells server which headers are included in the cross-origin request.\nResponse HTTP/1.1 204 No Content Access-Control-Allow-Origin: https://www.google.com Access-Control-Allow-Methods: GET,POST,PUT Access-Control-Allow-Headers: customer-header,x-customer-header Access-Control-Allow-Credentials Header # The Access-Control-Allow-Credentials response header tells browsers whether to expose the response to the frontend JavaScript code when the request\u0026rsquo;s credentials mode (Request.credentials) is include.\nIssue Demonstration # Make below call in your browser console under Google domain\nfetch(\u0026#34;http://localhost:3000\u0026#34;, { method: \u0026#34;PUT\u0026#34;, credentials: \u0026#34;include\u0026#34; }).then((req) =\u0026gt; req.json()).then(console.log); You will see error message:\nAccess to fetch at \u0026#39;http://localhost:3000/\u0026#39; from origin \u0026#39;https://www.google.com\u0026#39; has been blocked by CORS policy: Response to preflight request doesn\u0026#39;t pass access control check: The value of the \u0026#39;Access-Control-Allow-Credentials\u0026#39; header in the response is \u0026#39;\u0026#39; which must be \u0026#39;true\u0026#39; when the request\u0026#39;s credentials mode is \u0026#39;include\u0026#39;. That is because you want to include credentials, including cookies, authorization headers, or TLS client certificates, in your request.\nRemember if you don\u0026rsquo;t explicitly specify credentials: \u0026quot;include\u0026quot; in your request, cookies will not be added in your request\u0026rsquo;s headers\nSolution # Set credentials to true in server\u0026rsquo;s CORS config\napp.use(cors({ origin: \u0026#34;https://www.google.com\u0026#34;, methods: [\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;], credentials: true })); Access-Control-Allow-Headers Header # Used in response to a preflight request to indicate which HTTP headers can be used when making the actual request.\nProblem Demonstration # Limit Content-Type as the only header which server allowed\napp.use(cors({ origin: \u0026#34;https://www.google.com\u0026#34;, methods: [\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;], allowedHeaders: [\u0026#39;Content-Type\u0026#39;] })); Then make a call from Google domain with two customer headers\nfetch(\u0026#34;http://localhost:3000\u0026#34;, { method: \u0026#34;PUT\u0026#34;, headers: { \u0026#34;Customer-Header\u0026#34;: \u0026#34;key=value\u0026#34;, \u0026#34;X-Customer-Header\u0026#34;: \u0026#34;key=value\u0026#34;, \u0026#34;Cookie\u0026#34;: \u0026#34;value\u0026#34; } }).then((req) =\u0026gt; req.json()).then(console.log); The request was denied with below error message\nAccess to fetch at \u0026#39;http://localhost:3000/\u0026#39; from origin \u0026#39;https://www.google.com\u0026#39; has been blocked by CORS policy: Request header field customer-header is not allowed by Access-Control-Allow-Headers in preflight response. Solution # Add customers header as allowed headers\napp.use(cors({ origin: \u0026#34;https://www.google.com\u0026#34;, methods: [\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34;], allowedHeaders: [\u0026#34;Content-Type\u0026#34;, \u0026#34;Customer-Header\u0026#34;, \u0026#34;X-Customer-Header\u0026#34;], })); Reference # YouTube video CORS Preflight Request Access-Control-Allow-Credentials "},{"id":34,"href":"/docs/programming/web/web-api/web-storage-api/","title":"Web Storage Api","section":"Web API","content":" Definition # The Web Storage API provides mechanisms by which browsers can store key/value pairs\nSource code # These mechanisms are available via the Window.sessionStorage and Window.localStorage properties (to be more precise, the Window object implements the WindowLocalStorage and WindowSessionStorage objects, which the localStorage and sessionStorage properties hang off) ‚Äî invoking one of these will create an instance of the Storage object, through which data items can be set, retrieved and removed. A different Storage object is used for the sessionStorage and localStorage for each origin ‚Äî they function and are controlled separately.\ninterface Window extends WindowLocalStorage, WindowSessionStorage { ... } interface WindowSessionStorage { readonly sessionStorage: Storage; } interface WindowLocalStorage { readonly localStorage: Storage; } interface Storage { readonly length: number; clear(): void; getItem(key: string): string | null; key(index: number): string | null; removeItem(key: string): void; setItem(key: string, value: string): void; [name: string]: any; } Property # The read-only sessionStorage property accesses a session Storage object for the current origin. sessionStorage is similar to localStorage; the difference is that while data in localStorage doesn\u0026rsquo;t expire, data in sessionStorage is cleared when the page session ends.\nData stored in sessionStorage and localStorage is specific to the protocol of the page. In particular, data stored by a script on a site accessed with HTTP (e.g., http://example.com) is put in a different sessionStorage object from the same site accessed with HTTPS (e.g., https://example.com).\nThe keys and the values are always in the UTF-16 string format, which uses two bytes per character. As with objects, integer keys are automatically converted to strings.\nReference # https://developer.mozilla.org/en-US/docs/Web/API/Web_Storage_API#web_storage_concepts_and_usage YouTube video with examples "},{"id":35,"href":"/docs/programming/web/http/cookie/","title":"Cookie","section":"HTTP","content":" What is cookie # An HTTP cookie (web cookie, browser cookie) is a small piece of data that a server sends to a user\u0026rsquo;s web browser. The browser may store the cookie and send it back to the same server with later requests. Typically, an HTTP cookie is used to tell if two requests come from the same browser‚Äîkeeping a user logged in, for example. It remembers stateful information for the stateless HTTP protocol.\nCookies are created by server Cookies are stored in client\u0026rsquo;s browser Cookies are sent with every request to the same domain (Explain more below) Deprecation of cookie # Cookies were once used for general client-side storage. While this made sense when they were the only way to store data on the client, modern storage APIs are now recommended. Cookies are sent with every request, so they can worsen performance (especially for mobile data connections). Modern APIs for client storage are the Web Storage API (localStorage and sessionStorage) and IndexedDB.\nUse case of cookie # Session management Logins, shopping carts, game scores, or anything else the server should remember\nPersonalization User preferences, themes, and other settings\nYou visited a weather website and entered your address to get weather information. The server set an address cookie under the domain of the weather website. Next time when you revisit the website, the address cookie will be sent in the request\u0026rsquo;s header, and the website will show weather information of same address. Tracking Recording and analyzing user behavior (ADs)\nHow to set cookies # Cookies can be set and modified at the server level using\nthe Set-Cookie HTTP header, or with JavaScript using document.cookie. After receiving an HTTP request, a server can send one or more Set-Cookie headers with the response. The browser usually stores the cookie and sends it with requests made to the same server inside a Cookie HTTP header.\nSet-Cookie and Cookie headers # The Set-Cookie HTTP response header sends cookies from the server to the user agent. A simple cookie is set like this:\nSet-Cookie: \u0026lt;cookie-name\u0026gt;=\u0026lt;cookie-value\u0026gt; Example:\nHTTP/2.0 200 OK Content-Type: text/html Set-Cookie: yummy_cookie=choco Set-Cookie: tasty_cookie=strawberry [page content] Define the lifecycle of a cookie # The lifetime of a cookie can be defined in two ways:\nSession cookies are deleted when the current session ends. The browser defines when the \u0026ldquo;current session\u0026rdquo; ends, and some browsers use session restoring when restarting. This can cause session cookies to last indefinitely. Permanent cookies are deleted at a date specified by the Expires attribute, or after a period of time specified by the Max-Age attribute. Example: Set-Cookie: id=a3fWa; Expires=Thu, 31 Oct 2021 07:28:00 GMT; Restrict access to cookies # Secure attribute A cookie with the Secure attribute is only sent to the server with an encrypted request over the HTTPS protocol. HttpOnly attribute A cookie with the HttpOnly attribute is inaccessible to the JavaScript Document.cookie API; it\u0026rsquo;s only sent to the server. For example, cookies that persist in server-side sessions don\u0026rsquo;t need to be available to JavaScript and should have the HttpOnly attribute. This precaution helps mitigate cross-site scripting (XSS) attacks. Example: Set-Cookie: id=a3fWa; Expires=Thu, 21 Oct 2021 07:28:00 GMT; Secure; HttpOnly Define where cookies are sent # The Domain and Path attributes define the scope of a cookie: what URLs the cookies should be sent to.\nDomain attribute # The Domain attribute specifies which hosts can receive a cookie. If the server does not specify a Domain, the browser defaults the domain to the same host that set the cookie, excluding subdomains. If Domain is specified, then subdomains are always included. Therefore, specifying Domain is less restrictive than omitting it. However, it can be helpful when subdomains need to share information about a user.\nFor example, if you set Domain=mozilla.org, cookies are available on domains like\nmozilla.orgdeveloper.mozilla.org If the the cookie was set by server with domain example.com, and no domain attribute was specified. Then the cookie will only be send to domain example.com.\nPath attribute # The Path attribute indicates a URL path that must exist in the requested URL in order to send the Cookie header. The (\u0026quot;/\u0026quot;) character is considered a directory separator, and subdirectories match as well. For example, if you set Path=/docs, these request paths match:\n/docs/docs//docs/Web//docs/Web/HTTP But these request paths don\u0026rsquo;t:\n//docsets/fr/docs TODO # There are still some other attributes and concepts regarding cookie, will dive deeper later is necessary Attach some picture about Set-Cookie and Cookie headers, and attributes of a cookie Dive deeper for HttpOnly attribute Reference # Cookie Definition Nice YouTube video "},{"id":36,"href":"/docs/programming/tools/hugo/set-up-hugo-in-git-hub-pages/","title":"Set Up Hugo in Git Hub Pages","section":"Hugo","content":" Create a repository to hold the source code of your blogs # Create a repository of Git Hub Pages # Create a new Hugo project in your local machine # cd ~/Projects hugo new site \u0026lt;site name\u0026gt; cd \u0026lt;site name\u0026gt; git init git remote add origin \u0026lt;repository URL of your blogs\u0026gt; git add . git commit -m \u0026#34;Initiate a new hugo project\u0026#34; git push origin main Choose theme for your blog site # Navigate to Hugo theme website Down your favorite theme to directory ~/Projects/\u0026lt;site name\u0026gt;/themes Modify your config file baseURL = \u0026#34;https://\u0026lt;URL of your Git Hub Pages\u0026gt;/\u0026#34; languageCode = \u0026#34;en-us\u0026#34; title = \u0026#34;\u0026lt;website name\u0026gt;\u0026#34; theme = \u0026#34;\u0026lt;theme name\u0026gt;\u0026#34; Run hugo server to check if everything in your local host is expected Add Git Hub Pages repository as submodule of your source repository # cd ~/Projects/\u0026lt;site name\u0026gt; git submodule add -b main \u0026lt;URL of your Git Hub Pages\u0026gt; public # Generate static resouce in public directory hugo cd public git add . git commit -m \u0026#34;\u0026#34;Initiate a new hugo project\u0026#34; git push origin main "}]